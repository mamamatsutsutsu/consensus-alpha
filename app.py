import streamlit as st
import pandas as pd
import yfinance as yf
import plotly.graph_objects as go
from google import genai
import json
from io import StringIO
from datetime import datetime, timezone
import time
import requests
import xml.etree.ElementTree as ET

# --- 1. è¨­å®š & ã‚»ã‚¯ã‚¿ãƒ¼è¾æ›¸ ---
st.set_page_config(page_title="ConsensusAlpha v5.2", layout="wide")
st.title("ğŸ§  ConsensusAlpha v5.2: 200éŠ˜æŸ„ãƒ»ç²¾å¯†åˆ†æã‚¨ãƒ³ã‚¸ãƒ³")

# éŠ˜æŸ„ãƒªã‚¹ãƒˆï¼ˆæ—¥ç±³åˆè¨ˆç´„200éŠ˜æŸ„è¦æ¨¡ã¸ã®æ‹¡å¼µä¾‹ï¼‰
SECTOR_CATALOG = {
    "ç±³å›½æ ª (US)": {
        "ãƒã‚°ãƒ‹ãƒ•ã‚£ã‚»ãƒ³ãƒˆ7": {"AAPL": "Apple", "MSFT": "Microsoft", "GOOGL": "Alphabet", "AMZN": "Amazon", "NVDA": "NVIDIA", "META": "Meta", "TSLA": "Tesla"},
        "åŠå°ä½“ãƒ»AI": {"AVGO": "Broadcom", "AMD": "AMD", "ASML": "ASML", "TSM": "TSMC", "INTC": "Intel", "QCOM": "Qualcomm", "MU": "Micron", "ARM": "Arm", "LRCX": "Lam Research", "AMAT": "Applied Materials"},
        "é‡‘èãƒ»æ±ºæ¸ˆ": {"JPM": "JP Morgan", "V": "Visa", "MA": "Mastercard", "BAC": "Bank of America", "GS": "Goldman Sachs", "MS": "Morgan Stanley", "AXP": "American Express"},
        "ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢": {"LLY": "Eli Lilly", "UNH": "UnitedHealth", "JNJ": "J&J", "NVO": "Novo Nordisk", "ABBV": "AbbVie", "MRK": "Merck", "PFE": "Pfizer", "TMO": "Thermo Fisher"},
        "æ¶ˆè²»è²¡ãƒ»å°å£²": {"WMT": "Walmart", "PG": "P&G", "KO": "Coca-Cola", "PEP": "PepsiCo", "COST": "Costco", "NKE": "Nike", "MCD": "McDonald's", "DIS": "Disney"}
    },
    "æ—¥æœ¬æ ª (JP)": {
        "åŠå°ä½“ãƒ»ãƒã‚¤ãƒ†ã‚¯": {"8035": "æ±äº¬ã‚¨ãƒ¬ã‚¯ãƒˆãƒ­ãƒ³", "6857": "ã‚¢ãƒ‰ãƒãƒ³ãƒ†ã‚¹ãƒˆ", "6758": "ã‚½ãƒ‹ãƒ¼", "6723": "ãƒ«ãƒã‚µã‚¹", "6146": "ãƒ‡ã‚£ã‚¹ã‚³", "6920": "ãƒ¬ãƒ¼ã‚¶ãƒ¼ãƒ†ãƒƒã‚¯", "6501": "æ—¥ç«‹", "6702": "å¯Œå£«é€š", "6645": "ã‚ªãƒ ãƒ­ãƒ³"},
        "é‡‘èãƒ»ãƒ¡ã‚¬ãƒãƒ³ã‚¯": {"8306": "ä¸‰è±UFJ", "8316": "ä¸‰äº•ä½å‹", "8411": "ã¿ãšã»", "8766": "æ±äº¬æµ·ä¸Š", "8591": "ã‚ªãƒªãƒƒã‚¯ã‚¹", "8308": "ã‚Šããª", "8604": "é‡æ‘HD", "8725": "MS&AD"},
        "è‡ªå‹•è»Šãƒ»è¼¸é€": {"7203": "ãƒˆãƒ¨ã‚¿", "7267": "ãƒ›ãƒ³ãƒ€", "6902": "ãƒ‡ãƒ³ã‚½ãƒ¼", "7201": "æ—¥ç”£", "7261": "ãƒãƒ„ãƒ€", "7270": "SUBARU", "7011": "ä¸‰è±é‡å·¥", "7012": "å·å´é‡å·¥", "7013": "IHI"},
        "ç·åˆå•†ç¤¾": {"8058": "ä¸‰è±å•†äº‹", "8001": "ä¼Šè—¤å¿ ", "8031": "ä¸‰äº•ç‰©ç”£", "8053": "ä½å‹å•†äº‹", "8015": "è±Šç”°é€šå•†", "2768": "åŒæ—¥", "8002": "ä¸¸ç´…"},
        "é€šä¿¡ãƒ»å°å£²ãƒ»ãã®ä»–": {"9432": "NTT", "9433": "KDDI", "9984": "ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯G", "9983": "ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆãƒªãƒ†ã‚¤ãƒªãƒ³ã‚°", "7114": "ã‚»ãƒ–ãƒ³ï¼†ã‚¢ã‚¤", "4502": "æ­¦ç”°è–¬å“", "2802": "å‘³ã®ç´ ", "1925": "å¤§å’Œãƒã‚¦ã‚¹"}
    }
}

# --- 2. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ ---
api_key = st.secrets.get("GEMINI_API_KEY")
if not api_key:
    st.error("ğŸ”‘ Secretsã« GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()
client = genai.Client(api_key=api_key)

# --- 3. ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ & ã‚­ãƒ£ãƒƒã‚·ãƒ¥ ---

@st.cache_data(ttl=3600)
def fetch_price_stooq(ticker, market_suffix):
    """ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä¼´ã†ä¾¡æ ¼å–å¾—"""
    suffixes = [market_suffix.lower(), "jp", "jpn"] if market_suffix == "JP" else [market_suffix.lower()]
    for s in suffixes:
        url = f"https://stooq.com/q/d/l/?s={ticker.lower()}.{s}&i=d"
        try:
            r = requests.get(url, timeout=10)
            df = pd.read_csv(StringIO(r.content.decode("utf-8")))
            if "Close" in df.columns and not df.empty:
                df["Date"] = pd.to_datetime(df["Date"])
                return df.set_index("Date").sort_index(), s
        except: continue
    return None, None

@st.cache_data(ttl=86400)
def fetch_fundamentals_yf(ticker, market_suffix):
    yf_ticker = f"{ticker}.T" if market_suffix == "JP" else ticker
    try:
        tk = yf.Ticker(yf_ticker)
        info = tk.info
        return {"market_cap": info.get("marketCap"), "per": info.get("trailingPE"), "pbr": info.get("priceToBook")}
    except: return {"market_cap": None, "per": None, "pbr": None}

@st.cache_data(ttl=900) # ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚‚15åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def fetch_news(ticker, name, market_suffix):
    lang, gl, ceid = ("en-US", "US", "US:en") if market_suffix == "US" else ("ja-JP", "JP", "JP:ja")
    # åç§°ãŒãªã„ï¼ˆè¿½åŠ éŠ˜æŸ„ï¼‰å ´åˆã¯ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã®ã¿
    query = f"{name} {ticker}" if name != ticker else f"{ticker} stock"
    url = f"https://news.google.com/rss/search?q={query}&hl={lang}&gl={gl}&ceid={ceid}"
    try:
        r = requests.get(url, timeout=5)
        root = ET.fromstring(r.text)
        return list(set([item.find('title').text for item in root.findall('.//item')[:5]]))
    except: return []

# --- 4. ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ»ã‚¨ãƒ³ã‚¸ãƒ³ ---

def calculate_logic_score(m):
    """Pythonã«ã‚ˆã‚‹æ±ºå®šè«–çš„ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚° (ã‚¢ãƒ‰ãƒã‚¤ã‚¹åæ˜ ç‰ˆ)"""
    score = 0
    # 1. ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ  (40%)
    if m.get("mom_12_1") is not None:
        score += m["mom_12_1"] * 0.4
    else:
        score -= 5 # ãƒ‡ãƒ¼ã‚¿æ¬ æãƒšãƒŠãƒ«ãƒ†ã‚£
    
    # 2. ä½ãƒœãƒ©åŠ ç‚¹ (ä¿®æ­£ï¼šã‚­ãƒ¼åã‚’ vol_60d ã«çµ±ä¸€)
    if m.get("vol_60d") is not None:
        score += (30 - m["vol_60d"]) * 0.2
    
    # 3. å‰²å®‰æ€§ (ä¿®æ­£ï¼šPERåŠ ç‚¹ã«ä¸Šé™è¨­å®š)
    if m.get("per") is not None and m["per"] > 0:
        value_points = (15 / m["per"]) * 10
        score += min(value_points, 15) # æœ€å¤§15ç‚¹ã«åˆ¶é™ã—ã¦ç•°å¸¸å€¤ã‚’é˜²ã
    else:
        score -= 2
    
    # 4. ãƒªã‚¹ã‚¯æ¸›ç‚¹ (DDã‚’ãã®ã¾ã¾åŠ ç®—)
    score += abs(m["max_dd_period"]) * -0.3
    return round(score, 2)

# --- 5. ãƒ¡ã‚¤ãƒ³ UI ---

st.sidebar.header("ğŸ“ ã‚»ã‚¯ã‚¿ãƒ¼æˆ¦ç•¥")
market_choice = st.sidebar.selectbox("å¸‚å ´", list(SECTOR_CATALOG.