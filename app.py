import streamlit as st
import pandas as pd
import yfinance as yf
import plotly.graph_objects as go
from google import genai
import json
from io import StringIO
from urllib.parse import quote_plus
import time
import requests
import xml.etree.ElementTree as ET

# --- 1. è¨­å®š & 200éŠ˜æŸ„ã‚»ã‚¯ã‚¿ãƒ¼ã‚«ã‚¿ãƒ­ã‚° ---
st.set_page_config(page_title="ConsensusAlpha v5.3.1", layout="wide")
st.title("ğŸ§  ConsensusAlpha v5.3.1: ã‚»ã‚¯ã‚¿ãƒ¼å§”å“¡ä¼šãƒ»é«˜ç²¾åº¦ç‰ˆ")

SECTOR_CATALOG = {
    "ç±³å›½æ ª (US)": {
        "ãƒã‚°ãƒ‹ãƒ•ã‚£ã‚»ãƒ³ãƒˆ7": {"AAPL": "Apple", "MSFT": "Microsoft", "GOOGL": "Alphabet", "AMZN": "Amazon", "NVDA": "NVIDIA", "META": "Meta", "TSLA": "Tesla"},
        "åŠå°ä½“ç²¾é‹­": {"AVGO": "Broadcom", "AMD": "AMD", "ASML": "ASML", "TSM": "TSMC", "ARM": "Arm", "MU": "Micron", "LRCX": "Lam Research"},
        "é‡‘èãƒ»æ±ºæ¸ˆ": {"JPM": "JP Morgan", "V": "Visa", "MA": "Mastercard", "BAC": "Bank of America", "GS": "Goldman Sachs", "AXP": "American Express"}
    },
    "æ—¥æœ¬æ ª (JP)": {
        "åŠå°ä½“ãƒ»ãƒã‚¤ãƒ†ã‚¯": {"8035": "æ±äº¬ã‚¨ãƒ¬ã‚¯ãƒˆãƒ­ãƒ³", "6857": "ã‚¢ãƒ‰ãƒãƒ³ãƒ†ã‚¹ãƒˆ", "6758": "ã‚½ãƒ‹ãƒ¼", "6723": "ãƒ«ãƒã‚µã‚¹", "6146": "ãƒ‡ã‚£ã‚¹ã‚³", "6920": "ãƒ¬ãƒ¼ã‚¶ãƒ¼ãƒ†ãƒƒã‚¯", "6501": "æ—¥ç«‹"},
        "é‡‘èãƒ»ãƒ¡ã‚¬ãƒãƒ³ã‚¯": {"8306": "ä¸‰è±UFJ", "8316": "ä¸‰äº•ä½å‹", "8411": "ã¿ãšã»", "8766": "æ±äº¬æµ·ä¸Š", "8591": "ã‚ªãƒªãƒƒã‚¯ã‚¹", "8604": "é‡æ‘HD"},
        "è‡ªå‹•è»Šãƒ»é‡å·¥æ¥­": {"7203": "ãƒˆãƒ¨ã‚¿", "7267": "ãƒ›ãƒ³ãƒ€", "6902": "ãƒ‡ãƒ³ã‚½ãƒ¼", "7011": "ä¸‰è±é‡å·¥", "7012": "å·å´é‡å·¥", "7013": "IHI"}
    }
}

# --- 2. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š ---
api_key = st.secrets.get("GEMINI_API_KEY")
if not api_key:
    st.error("ğŸ”‘ Secretsã« GEMINI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()
client = genai.Client(api_key=api_key)

# --- 3. é«˜ç²¾åº¦ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ³ã‚¸ãƒ³ ---

@st.cache_data(ttl=3600)
def fetch_data(ticker, market_suffix):
    suffixes = [market_suffix.lower(), "jp", "jpn"] if market_suffix == "JP" else [market_suffix.lower()]
    for s in suffixes:
        url = f"https://stooq.com/q/d/l/?s={ticker.lower()}.{s}&i=d"
        try:
            r = requests.get(url, timeout=10)
            df = pd.read_csv(StringIO(r.content.decode("utf-8")))
            if "Close" in df.columns and not df.empty:
                df["Date"] = pd.to_datetime(df["Date"])
                return df.set_index("Date").sort_index(), s
        except: continue
    return None, None

@st.cache_data(ttl=86400)
def fetch_info(ticker, market_suffix):
    yf_ticker = f"{ticker}.T" if market_suffix == "JP" else ticker
    try:
        tk = yf.Ticker(yf_ticker)
        info = tk.info
        return {"per": info.get("trailingPE"), "pbr": info.get("priceToBook")}
    except: return {"per": None, "pbr": None}

@st.cache_data(ttl=900)
def fetch_news(ticker, name, market_suffix):
    """URLã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã«ã‚ˆã‚‹æ—¥æœ¬èªå¯¾å¿œãƒ‹ãƒ¥ãƒ¼ã‚¹æ¤œç´¢"""
    lang, gl, ceid = ("en-US", "US", "US:en") if market_suffix == "US" else ("ja-JP", "JP", "JP:ja")
    # ã‚¢ãƒ‰ãƒã‚¤ã‚¹åæ˜ ï¼šä¼šç¤¾åã¨ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    query = quote_plus(f"{name} {ticker}")
    url = f"https://news.google.com/rss/search?q={query}&hl={lang}&gl={gl}&ceid={ceid}"
    try:
        r = requests.get(url, timeout=5)
        root = ET.fromstring(r.text)
        return [item.find('title').text for item in root.findall('.//item')[:3]]
    except: return []

# --- 4. å³æ ¼ãªã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚° ---

def calculate_logic_score(m):
    score = 0
    # 1. 12-1ãƒ¶æœˆãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ  (40%)
    if m.get("mom_12_1") is not None: score += m["mom_12_1"] * 0.4
    else: score -= 5 # æ¬ æãƒšãƒŠãƒ«ãƒ†ã‚£
    
    # 2. ä½ãƒœãƒ©åŠ ç‚¹ (30%åŸºæº–)
    if m.get("vol_60d") is not None: score += (30 - m["vol_60d"]) * 0.2
    
    # 3. å‰²å®‰æ€§ (PERä¸Šé™15ç‚¹ã€æ¬ ææ™‚ãƒšãƒŠãƒ«ãƒ†ã‚£)
    if m.get("per") is not None and m["per"] > 0:
        score += min((15 / m["per"]) * 10, 15)
    else:
        score -= 2 # è²¡å‹™ä¸æ˜ãƒšãƒŠãƒ«ãƒ†ã‚£
        
    # 4. æœŸé–“ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³
    score += abs(m["max_dd_period"]) * -0.3
    return round(score, 2)

# --- 5. ãƒ¡ã‚¤ãƒ³ UI ---

st.sidebar.header("ğŸ“ ã‚»ã‚¯ã‚¿ãƒ¼æˆ¦ç•¥è¨­å®š")
market_choice = st.sidebar.selectbox("å¸‚å ´", list(SECTOR_CATALOG.keys()))
sector_choice = st.sidebar.selectbox("ã‚»ã‚¯ã‚¿ãƒ¼", list(SECTOR_CATALOG[market_choice].keys()))
period_choice = st.sidebar.selectbox("åˆ†æã‚¹ãƒ‘ãƒ³", ["3ãƒ¶æœˆ", "1å¹´", "3å¹´"], index=1)

DD_LIMIT = {"3ãƒ¶æœˆ": -20.0, "1å¹´": -35.0, "3å¹´": -50.0}[period_choice]
TICKER_MAP = SECTOR_CATALOG[market_choice][sector_choice]

if st.sidebar.button(f"ğŸš€ {sector_choice}ãƒ»ç²¾å¯†è©•è­°ã‚’é–‹å§‹"):
    results = []
    market_suffix = "US" if "US" in market_choice else "JP"
    
    with st.status("ã‚»ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆä¸­...", expanded=True) as status:
        for t, name in TICKER_MAP.items():
            st.write(f"ğŸ“¡ {name} ({t}) ã®å…¨æŒ‡æ¨™ã‚’ç²¾æŸ»ä¸­...")
            df, s_used = fetch_data(t, market_suffix)
            if df is not None:
                c = df["Close"].astype(float)
                days = {"3ãƒ¶æœˆ": 63, "1å¹´": 252, "3å¹´": 756}[period_choice]
                ref = min(len(c), days + 1)
                
                # æŒ‡æ¨™è¨ˆç®— (mom_12_1 ã‚’æ˜ç¤º)
                mom_12_1 = None
                if len(c) >= 252:
                    r252 = (c.iloc[-1]/c.iloc[-252]-1)*100
                    r21 = (c.iloc[-1]/c.iloc[-21]-1)*100
                    mom_12_1 = r252 - r21
                
                vol = c.pct_change().rolling(60).std().iloc[-1] * (252**0.5) * 100 if len(c)>60 else None
                sub = c.iloc[-ref:]
                dd = ((sub / sub.cummax() - 1) * 100).min()
                
                if dd >= DD_LIMIT:
                    info = fetch_info(t, market_suffix)
                    m = {
                        "ticker": t, "name": name, "st_symbol": f"{t}.{s_used}",
                        "price": round(c.iloc[-1], 2), "mom_12_1": round(mom_12_1, 2) if mom_12_1 is not None else None,
                        "vol_60d": vol, "max_dd_period": round(dd, 2), **info, "history": sub
                    }
                    m["score"] = calculate_logic_score(m)
                    m["news"] = fetch_news(t, name, market_suffix)
                    results.append(m)
            time.sleep(0.1)
        status.update(label="ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†", state="complete")

    if results:
        results = sorted(results, key=lambda x: x["score"], reverse=True)
        
        # ã‚°ãƒ©ãƒ•è¡¨ç¤º
        st.header(f"ğŸ“ˆ {sector_choice}ï¼šç›¸å¯¾ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ ({period_choice})")
        
        fig = go.Figure()
        for r in results:
            norm = (r["history"] / r["history"].iloc[0]) * 100
            fig.add_trace(go.Scatter(x=norm.index, y=norm, name=r["name"]))
        fig.update_layout(height=450, yaxis_title="æŒ‡æ•° (é–‹å§‹æ—¥=100)")
        st.plotly_chart(fig, use_container_width=True)

        # AIãƒ¬ãƒãƒ¼ãƒˆ (æŒ‡ç¤ºã®å¼·åŒ–)
        ai_payload = [{k: v for k, v in r.items() if k != 'history'} for r in results]
        prompt = f"""
        ã‚ãªãŸã¯æŠ•è³‡å§”å“¡ä¼šã®è­°é•·ã§ã™ã€‚{sector_choice}ã‚»ã‚¯ã‚¿ãƒ¼ã®ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’å…ƒã«ã€ç·åˆé †ä½ã‚’æ±ºå®šã—ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
        
        ã€è©•è­°ã®ãƒ«ãƒ¼ãƒ«ã€‘
        1. Pythonã‚¹ã‚³ã‚¢ã‚’åŸºæœ¬ã¨ã™ã‚‹ãŒã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚„PER/PBRã‚’å…ƒã«é †ä½ã‚’æœ€å¤§2åã¾ã§å…¥ã‚Œæ›¿ãˆã¦ã‚‚ã‚ˆã„ï¼ˆãã®å ´åˆã¯ç†ç”±ã‚’æ˜è¨˜ï¼‰ã€‚
        2. å„éŠ˜æŸ„ã®è©•ä¾¡ã§ã¯ã€å¿…ãšã€Œmom_12_1ã€ã€ŒPERã€ã€Œmax_dd_periodã€ã®æ•°å€¤ã‚’å¼•ç”¨ã—ã¦èª¬æ˜ã™ã‚‹ã“ã¨ã€‚
        3. ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒãªã„éŠ˜æŸ„ã¯ã€Œãƒ‹ãƒ¥ãƒ¼ã‚¹ã«ã‚ˆã‚‹åˆ¤æ–­ä¸èƒ½ã€ã¨æ˜è¨˜ã—ã€æ†¶æ¸¬ã§æ›¸ã‹ãªã„ã“ã¨ã€‚
        
        ã€ã‚»ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã€‘
        {json.dumps(ai_payload, ensure_ascii=False)}
        """
        
        try:
            # ãƒ¢ãƒ‡ãƒ«åã‚’å®‰å®šç‰ˆ gemini-flash-latest ã«
            response = client.models.generate_content(model='gemini-flash-latest', contents=prompt)
            col1, col2 = st.columns([1, 1])
            with col1:
                st.header("ğŸ† å§”å“¡ä¼šã«ã‚ˆã‚‹ç·åˆè©•è­°ãƒ¬ãƒãƒ¼ãƒˆ")
                st.markdown(response.text)
            with col2:
                st.header("ğŸ“‹ ã‚»ã‚¯ã‚¿ãƒ¼ãƒ»ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ä¸€è¦§")
                st.dataframe(pd.DataFrame([{k:v for k,v in r.items() if k not in ['history', 'news']} for r in results]))
        except Exception as e:
            st.error("AIãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚å³å´ã®ãƒ‡ãƒ¼ã‚¿ä¸€è¦§ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")