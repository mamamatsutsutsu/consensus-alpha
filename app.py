import streamlit as st
import pandas as pd
import yfinance as yf
import plotly.graph_objects as go
from google import genai
import json
from io import StringIO
from datetime import datetime, timezone
import time
import requests
import xml.etree.ElementTree as ET

# --- 1. è¨­å®š & 200éŠ˜æŸ„ã‚«ã‚¿ãƒ­ã‚° ---
st.set_page_config(page_title="ConsensusAlpha v5.2.1", layout="wide")
st.title("ğŸ§  ConsensusAlpha v5.2.1: 200éŠ˜æŸ„ãƒ»ç²¾å¯†åˆ†æã‚¨ãƒ³ã‚¸ãƒ³")

SECTOR_CATALOG = {
    "ç±³å›½æ ª (US)": {
        "ãƒã‚°ãƒ‹ãƒ•ã‚£ã‚»ãƒ³ãƒˆ7": {"AAPL": "Apple", "MSFT": "Microsoft", "GOOGL": "Alphabet", "AMZN": "Amazon", "NVDA": "NVIDIA", "META": "Meta", "TSLA": "Tesla"},
        "åŠå°ä½“ãƒ»AI": {"AVGO": "Broadcom", "AMD": "AMD", "ASML": "ASML", "TSM": "TSMC", "INTC": "Intel", "QCOM": "Qualcomm", "MU": "Micron", "ARM": "Arm", "LRCX": "Lam Research", "AMAT": "Applied Materials"},
        "é‡‘èãƒ»æ±ºæ¸ˆ": {"JPM": "JP Morgan", "V": "Visa", "MA": "Mastercard", "BAC": "Bank of America", "GS": "Goldman Sachs", "MS": "Morgan Stanley", "AXP": "American Express"},
        "ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢": {"LLY": "Eli Lilly", "UNH": "UnitedHealth", "JNJ": "J&J", "NVO": "Novo Nordisk", "ABBV": "AbbVie", "MRK": "Merck", "PFE": "Pfizer"},
        "æ¶ˆè²»è²¡ãƒ»å°å£²": {"WMT": "Walmart", "PG": "P&G", "KO": "Coca-Cola", "PEP": "PepsiCo", "COST": "Costco", "NKE": "Nike", "MCD": "McDonald's"}
    },
    "æ—¥æœ¬æ ª (JP)": {
        "åŠå°ä½“ãƒ»ãƒã‚¤ãƒ†ã‚¯": {"8035": "æ±äº¬ã‚¨ãƒ¬ã‚¯ãƒˆãƒ­ãƒ³", "6857": "ã‚¢ãƒ‰ãƒãƒ³ãƒ†ã‚¹ãƒˆ", "6758": "ã‚½ãƒ‹ãƒ¼", "6723": "ãƒ«ãƒã‚µã‚¹", "6146": "ãƒ‡ã‚£ã‚¹ã‚³", "6920": "ãƒ¬ãƒ¼ã‚¶ãƒ¼ãƒ†ãƒƒã‚¯", "6501": "æ—¥ç«‹", "6702": "å¯Œå£«é€š"},
        "é‡‘èãƒ»ãƒ¡ã‚¬ãƒãƒ³ã‚¯": {"8306": "ä¸‰è±UFJ", "8316": "ä¸‰äº•ä½å‹", "8411": "ã¿ãšã»", "8766": "æ±äº¬æµ·ä¸Š", "8591": "ã‚ªãƒªãƒƒã‚¯ã‚¹", "8308": "ã‚Šããª", "8604": "é‡æ‘HD"},
        "è‡ªå‹•è»Šãƒ»è¼¸é€": {"7203": "ãƒˆãƒ¨ã‚¿", "7267": "ãƒ›ãƒ³ãƒ€", "6902": "ãƒ‡ãƒ³ã‚½ãƒ¼", "7201": "æ—¥ç”£", "7261": "ãƒãƒ„ãƒ€", "7270": "SUBARU", "7011": "ä¸‰è±é‡å·¥", "7013": "IHI"},
        "ç·åˆå•†ç¤¾": {"8058": "ä¸‰è±å•†äº‹", "8001": "ä¼Šè—¤å¿ ", "8031": "ä¸‰äº•ç‰©ç”£", "8053": "ä½å‹å•†äº‹", "8015": "è±Šç”°é€šå•†", "2768": "åŒæ—¥", "8002": "ä¸¸ç´…"},
        "é€šä¿¡ãƒ»å°å£²ãƒ»åŒ»è–¬": {"9432": "NTT", "9433": "KDDI", "9984": "ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯G", "9983": "ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆãƒªãƒ†ã‚¤ãƒªãƒ³ã‚°", "7114": "ã‚»ãƒ–ãƒ³ï¼†ã‚¢ã‚¤", "4502": "æ­¦ç”°è–¬å“", "2802": "å‘³ã®ç´ "}
    }
}

# --- 2. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ ---
api_key = st.secrets.get("GEMINI_API_KEY")
if not api_key:
    st.error("ğŸ”‘ Secretsã« GEMINI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()
client = genai.Client(api_key=api_key)

# --- 3. ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ä»˜ãå–å¾—ã‚¨ãƒ³ã‚¸ãƒ³ ---

@st.cache_data(ttl=3600)
def fetch_price_stooq(ticker, market_suffix):
    suffixes = [market_suffix.lower(), "jp", "jpn"] if market_suffix == "JP" else [market_suffix.lower()]
    for s in suffixes:
        url = f"https://stooq.com/q/d/l/?s={ticker.lower()}.{s}&i=d"
        try:
            r = requests.get(url, timeout=10)
            df = pd.read_csv(StringIO(r.content.decode("utf-8")))
            if "Close" in df.columns and not df.empty:
                df["Date"] = pd.to_datetime(df["Date"])
                return df.set_index("Date").sort_index(), s
        except: continue
    return None, None

@st.cache_data(ttl=86400)
def fetch_fundamentals_yf(ticker, market_suffix):
    yf_ticker = f"{ticker}.T" if market_suffix == "JP" else ticker
    try:
        tk = yf.Ticker(yf_ticker)
        info = tk.info
        return {"market_cap": info.get("marketCap"), "per": info.get("trailingPE"), "pbr": info.get("priceToBook")}
    except: return {"market_cap": None, "per": None, "pbr": None}

@st.cache_data(ttl=900)
def fetch_news(ticker, name, market_suffix):
    lang, gl, ceid = ("en-US", "US", "US:en") if market_suffix == "US" else ("ja-JP", "JP", "JP:ja")
    query = f"{name} {ticker}" if name != ticker else f"{ticker} stock"
    url = f"https://news.google.com/rss/search?q={query}&hl={lang}&gl={gl}&ceid={ceid}"
    try:
        r = requests.get(url, timeout=5)
        root = ET.fromstring(r.text)
        return list(set([item.find('title').text for item in root.findall('.//item')[:5]]))
    except: return []

# --- 4. ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ»ã‚¨ãƒ³ã‚¸ãƒ³ ---

def calculate_logic_score(m):
    score = 0
    # 1. ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ 
    if m.get("mom_12_1") is not None: score += m["mom_12_1"] * 0.4
    else: score -= 5
    # 2. ä½ãƒœãƒ©åŠ ç‚¹
    if m.get("vol_60d") is not None: score += (30 - m["vol_60d"]) * 0.2
    # 3. å‰²å®‰æ€§ (ä¸Šé™15ç‚¹)
    if m.get("per") is not None and m["per"] > 0: score += min((15 / m["per"]) * 10, 15)
    else: score -= 2
    # 4. ãƒªã‚¹ã‚¯æ¸›ç‚¹
    score += abs(m["max_dd_period"]) * -0.3
    return round(score, 2)

# --- 5. ãƒ¡ã‚¤ãƒ³ UI ---

st.sidebar.header("ğŸ“ ã‚»ã‚¯ã‚¿ãƒ¼æˆ¦ç•¥")
market_choice = st.sidebar.selectbox("å¸‚å ´", list(SECTOR_CATALOG.keys()))
sector_choice = st.sidebar.selectbox("ã‚»ã‚¯ã‚¿ãƒ¼", list(SECTOR_CATALOG[market_choice].keys()))
period_choice = st.sidebar.selectbox("åˆ†ææœŸé–“", ["3ãƒ¶æœˆ", "1å¹´", "3å¹´"], index=1)

DD_THRESHOLD_MAP = {"3ãƒ¶æœˆ": -20.0, "1å¹´": -35.0, "3å¹´": -50.0}
RISK_DD_REJECT = DD_THRESHOLD_MAP[period_choice]

TICKER_MAP = SECTOR_CATALOG[market_choice][sector_choice]
tickers_input = st.sidebar.text_area("éŠ˜æŸ„ãƒªã‚¹ãƒˆ (ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š)", value=",".join(TICKER_MAP.keys()))
SELECTED_TICKERS = [t.strip() for t in tickers_input.split(",") if t.strip()]

if st.sidebar.button(f"ğŸš€ {sector_choice}ä¸€æ‹¬ç²¾æŸ»é–‹å§‹"):
    if not SELECTED_TICKERS:
        st.error("éŠ˜æŸ„ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    results = []
    progress_bar = st.progress(0)
    
    for i, t in enumerate(SELECTED_TICKERS):
        name = TICKER_MAP.get(t, t)
        market_suffix = "US" if "US" in market_choice else "JP"
        
        df, s_used = fetch_price_stooq(t, market_suffix)
        if df is not None:
            c = df["Close"].astype(float)
            days = {"3ãƒ¶æœˆ": 63, "1å¹´": 252, "3å¹´": 756}[period_choice]
            ref_idx = min(len(c), days + 1)
            
            mom_12_1 = None
            if len(c) >= 252:
                r252 = (c.iloc[-1]/c.iloc[-252]-1)*100
                r21 = (c.iloc[-1]/c.iloc[-21]-1)*100
                mom_12_1 = r252 - r21
            
            vol_60 = c.pct_change().rolling(60).std().iloc[-1] * (252**0.5) * 100 if len(c) > 60 else None
            sub = c.iloc[-ref_idx:]
            max_dd = ((sub / sub.cummax() - 1) * 100).min()
            
            if max_dd >= RISK_DD_REJECT:
                f = fetch_fundamentals_yf(t, market_suffix)
                m = {
                    "ticker": t, "name": name, "stooq": f"{t}.{s_used}",
                    "price": round(c.iloc[-1], 2), "vol_60d": vol_60,
                    "mom_12_1": round(mom_12_1, 2) if mom_12_1 is not None else None,
                    "max_dd_period": round(max_dd, 2), **f, "history": sub
                }
                m["score"] = calculate_logic_score(m)
                m["news"] = fetch_news(t, name, market_suffix)
                results.append(m)
        
        progress_bar.progress((i + 1) / len(SELECTED_TICKERS))

    if results:
        results = sorted(results, key=lambda x: x["score"], reverse=True)
        
        # ãƒãƒ£ãƒ¼ãƒˆ
        st.header(f"ğŸ“ˆ ç›¸å¯¾æ¯”è¼ƒ ({period_choice}ï¼šé–‹å§‹æ™‚=100)")
        fig = go.Figure()
        for r in results[:10]:
            norm = (r["history"] / r["history"].iloc[0]) * 100
            fig.add_trace(go.Scatter(x=norm.index, y=norm, name=r["name"]))
        st.plotly_chart(fig, use_container_width=True)

        # AI
        ai_payload = [{k: v for k, v in r.items() if k != 'history'} for r in results[:10]]
        prompt = f"ã‚ãªãŸã¯æŠ•è³‡è­°é•·ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’å…ƒã«åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ã€‚ãƒ‹ãƒ¥ãƒ¼ã‚¹ç„¡ã—ã¯ã€Œä¸èƒ½ã€ã¨ã™ã‚‹ã“ã¨ã€‚ãƒ‡ãƒ¼ã‚¿:{json.dumps(ai_payload, ensure_ascii=False)}"
        report = client.models.generate_content(model='gemini-flash-latest', contents=prompt)

        col1, col2 = st.columns([1, 1])
        with col1:
            st.header("ğŸ† å§”å“¡ä¼šãƒ¬ãƒãƒ¼ãƒˆ")
            st.markdown(report.text)
        with col2:
            st.header("ğŸ“‹ ã‚¹ã‚³ã‚¢æ˜ç´°")
            st.dataframe(pd.DataFrame([{k:v for k,v in r.items() if k not in ['history', 'news']} for r in results]))