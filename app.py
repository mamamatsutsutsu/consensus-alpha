import os
import time
import re
import math
import urllib.parse
import urllib.request
import traceback
import xml.etree.ElementTree as ET
import email.utils
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Any, Optional

import numpy as np
import pandas as pd
import plotly.express as px
import streamlit as st
import yfinance as yf

# ==========================================
# 0. SYSTEM CONFIGURATION
# ==========================================
st.set_page_config(
    page_title="AlphaLens Pro",
    layout="wide",
    initial_sidebar_state="expanded",
    page_icon="ğŸ¦…"
)

# Initialize Session State
if "system_logs" not in st.session_state: st.session_state.system_logs = []
if "user_access_granted" not in st.session_state: st.session_state.user_access_granted = False
if "selected_sector" not in st.session_state: st.session_state.selected_sector = None
if "last_market_key" not in st.session_state: st.session_state.last_market_key = None

def log_system_event(msg: str, level: str = "INFO"):
    timestamp = datetime.now().strftime("%H:%M:%S")
    entry = f"[{timestamp}] [{level}] {msg}"
    st.session_state.system_logs.append(entry)
    print(entry)

def error_boundary(func):
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            log_system_event(f"{func.__name__}: {str(e)}", "ERROR")
            st.error(f"âš ï¸ SYSTEM ERROR: {str(e)}")
            return None
    return wrapper

# ==========================================
# 1. PHANTOM UI (Professional High-End)
# ==========================================
st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Orbitron:wght@400;600;800;900&family=Noto+Sans+JP:wght@400;700&display=swap');

:root {
  --bg: #050505;
  --panel: #0a0a0a;
  --card: #121212;
  --border: #333333;
  --accent: #00f2fe;     /* Cyan */
  --accent-2: #ff0055;   /* Pink/Red */
  --accent-3: #00ff88;   /* Green */
  --text: #e0e0e0;
}

html, body, .stApp { background-color: var(--bg) !important; color: var(--text) !important; }
* { font-family: 'Noto Sans JP', sans-serif !important; letter-spacing: 0.02em !important; }
h1, h2, h3, .brand { font-family: 'Orbitron', sans-serif !important; }

/* HIDE DEFAULTS */
#MainMenu {visibility: hidden;} footer {visibility: hidden;} header {visibility: hidden;}

/* BRANDING */
h1, h2, h3, .brand {
  background: linear-gradient(90deg, #fff, #00f2fe);
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  font-weight: 900 !important;
  text-shadow: 0 0 20px rgba(0, 242, 254, 0.5);
  margin-bottom: 0px !important;
  padding-bottom: 5px;
}

/* CONTAINERS */
.deck { background: var(--panel); border-bottom: 1px solid var(--accent); padding: 15px; margin-bottom: 20px; }
.card { background: var(--card); border: 1px solid var(--border); border-radius: 4px; padding: 20px; margin-bottom: 15px; }

/* TABLE VISIBILITY FIX */
div[data-testid="stDataFrame"] { background-color: #151515 !important; border: 1px solid var(--border) !important; }
div[data-testid="stDataFrame"] * { color: #ffffff !important; font-size: 13px !important; }
[data-testid="stHeader"] { background-color: #222 !important; border-bottom: 2px solid var(--accent) !important; }

/* INPUTS */
div[data-baseweb="select"] > div { background-color: #111 !important; border-color: #444 !important; color: #fff !important; }
div[data-baseweb="popover"], div[data-baseweb="menu"] { background-color: #111 !important; border: 1px solid #444 !important; }
div[data-baseweb="option"] { color: #fff !important; }
li[data-baseweb="option"]:hover { background-color: #222 !important; color: #00f2fe !important; }
.stSelectbox label { color: #aaa !important; }

/* BUTTONS */
button {
  background-color: #111 !important; color: var(--accent) !important;
  border: 1px solid #333 !important; border-radius: 4px !important;
  font-weight: 700 !important; text-transform: uppercase;
}
button:hover { border-color: var(--accent) !important; box-shadow: 0 0 10px var(--accent) !important; color: #fff !important; }

/* 5-AGENT COUNCIL STYLES */
.agent-row {
    display: flex;
    align-items: baseline; 
    margin-bottom: 8px;
    padding: 8px 12px;
    border-radius: 4px;
    background: #0f0f0f;
    border-left-width: 4px;
    border-left-style: solid;
    font-size: 13px;
    line-height: 1.5;
}
.agent-label { font-weight: 900; margin-right: 10px; white-space: nowrap; font-family: 'Orbitron'; letter-spacing: 1px; min-width: 100px; }
.agent-fundamental { border-left-color: #00f2fe; } .agent-fundamental .agent-label { color: #00f2fe; }
.agent-sentiment { border-left-color: #ff0055; } .agent-sentiment .agent-label { color: #ff0055; }
.agent-valuation { border-left-color: #00ff88; } .agent-valuation .agent-label { color: #00ff88; }
.agent-skeptic { border-left-color: #ffcc00; } .agent-skeptic .agent-label { color: #ffcc00; }
.agent-risk { border-left-color: #888888; } .agent-risk .agent-label { color: #888888; }
.agent-verdict { border: 1px solid #fff; background: #1a1a1a; padding: 15px; margin-top: 15px; font-weight: bold; }
.agent-box { padding: 10px; background: #111; color: #888; font-size: 12px; }

/* MARKET PULSE */
.market-box {
    background: #080808; border: 1px solid #333; padding: 20px;
    margin-bottom: 20px; font-size: 14px; line-height: 1.8; color: #ddd;
}
.highlight { color: #00f2fe; font-weight: bold; }
.highlight-neg { color: #ff0055; font-weight: bold; }

/* REPORT */
.report-box {
    background: #111; border-top: 3px solid var(--accent);
    padding: 20px; margin-top: 10px; line-height: 1.8; color: #eee; font-size: 13px;
    white-space: pre-wrap;
}

/* METRICS */
.kpi-val { font-size: 20px; color: var(--accent); font-weight: 700; }
</style>
""", unsafe_allow_html=True)

# ==========================================
# 2. AUTH & AI SETUP
# ==========================================
API_KEY = st.secrets.get("GEMINI_API_KEY") or st.secrets.get("GOOGLE_API_KEY") or os.getenv("GOOGLE_API_KEY")
APP_PASS = st.secrets.get("APP_PASSWORD")

try:
    import google.generativeai as genai
    HAS_LIB = True
    if API_KEY: genai.configure(api_key=API_KEY)
except Exception as e:
    HAS_LIB = False
    log_system_event(f"GenAI Lib: {e}", "WARN")

def check_access():
    if not APP_PASS: return True
    if st.session_state.user_access_granted: return True
    col1, col2, col3 = st.columns([1,2,1])
    with col2:
        st.markdown("<br><br><h3 style='text-align:center'>SECURITY GATE</h3>", unsafe_allow_html=True)
        with st.form("access_form"):
            p = st.text_input("PASSCODE", type="password")
            if st.form_submit_button("UNLOCK", use_container_width=True):
                if p == APP_PASS:
                    st.session_state.user_access_granted = True
                    st.rerun()
                else: st.error("DENIED")
    return False

if not check_access(): st.stop()

# ==========================================
# 3. UNIVERSE DEFINITIONS
# ==========================================
LOOKBACKS = {"1W (5d)": 5, "1M (21d)": 21, "3M (63d)": 63, "12M (252d)": 252}
FETCH_PERIOD = "24mo"

US_SEC = {
    "Technology": "XLK", "Healthcare": "XLV", "Financials": "XLF", "Comm Services": "XLC",
    "Cons. Disc": "XLY", "Cons. Staples": "XLP", "Industrials": "XLI", "Energy": "XLE",
    "Materials": "XLB", "Utilities": "XLU", "Real Estate": "XLRE"
}

JP_SEC = {
    "é£Ÿå“(Foods)": "1617.T", "ã‚¨ãƒãƒ«ã‚®ãƒ¼(Energy)": "1618.T", "å»ºè¨­ãƒ»è³‡æ(Const)": "1619.T", 
    "ç´ æãƒ»åŒ–å­¦(Mat)": "1620.T", "åŒ»è–¬å“(Pharma)": "1621.T", "è‡ªå‹•è»Šãƒ»è¼¸é€(Auto)": "1622.T", 
    "é‰„é‹¼ãƒ»éé‰„(Steel)": "1623.T", "æ©Ÿæ¢°(Machinery)": "1624.T", "é›»æ©Ÿãƒ»ç²¾å¯†(Elec)": "1625.T", 
    "æƒ…å ±é€šä¿¡(Info)": "1626.T", "é›»åŠ›ãƒ»ã‚¬ã‚¹(Util)": "1627.T", "é‹è¼¸ãƒ»ç‰©æµ(Trans)": "1628.T", 
    "å•†ç¤¾ãƒ»å¸å£²(Trade)": "1629.T", "å°å£²(Retail)": "1630.T", "éŠ€è¡Œ(Bank)": "1631.T", 
    "é‡‘è(Fin)": "1632.T", "ä¸å‹•ç”£(RE)": "1633.T"
}

US_STOCKS = {
    "Technology": ["AAPL","MSFT","NVDA","AVGO","ORCL","CRM","ADBE","AMD","QCOM","TXN","INTU","IBM","NOW","AMAT","MU","LRCX","ADI","KLAC","SNPS","CDNS","PANW","CRWD","ANET","PLTR"],
    "Comm Services": ["GOOGL","META","NFLX","DIS","CMCSA","TMUS","VZ","T","CHTR","WBD","LYV","EA","TTWO","OMC","IPG"],
    "Healthcare": ["LLY","UNH","JNJ","ABBV","MRK","TMO","ABT","AMGN","PFE","ISRG","DHR","VRTX","GILD","REGN","BMY","CVS","CI","SYK","BSX","MDT","ZTS","HCA","MCK"],
    "Financials": ["JPM","BAC","WFC","V","MA","AXP","GS","MS","BLK","C","SCHW","SPGI","PGR","CB","MMC","KKR","BX","TRV","AFL","MET","PRU","ICE","COF"],
    "Cons. Disc": ["AMZN","TSLA","HD","MCD","NKE","SBUX","LOW","BKNG","TJX","CMG","MAR","HLT","YUM","LULU","GM","F","ROST","ORLY","AZO","DHI","LEN"],
    "Cons. Staples": ["PG","KO","PEP","COST","WMT","PM","MO","MDLZ","CL","KMB","GIS","KHC","KR","STZ","EL","TGT","DG","ADM","SYY"],
    "Industrials": ["GE","CAT","DE","HON","UNP","UPS","RTX","LMT","BA","MMM","ETN","EMR","ITW","WM","NSC","CSX","GD","NOC","TDG","PCAR","FDX","CTAS"],
    "Energy": ["XOM","CVX","COP","EOG","SLB","MPC","PSX","VLO","OXY","KMI","WMB","HAL","BKR","DVN","HES","FANG","TRGP","OKE"],
    "Materials": ["LIN","APD","SHW","FCX","ECL","NEM","DOW","DD","NUE","MLM","VMC","CTVA","PPG","ALB","CF","MOS"],
    "Utilities": ["NEE","DUK","SO","AEP","SRE","EXC","XEL","D","PEG","ED","EIX","WEC","AWK","ES","PPL","ETR"],
    "Real Estate": ["PLD","AMT","CCI","EQIX","SPG","PSA","O","WELL","DLR","AVB","EQR","VICI","CSGP","SBAC","IRM"],
}

JP_STOCKS = {
    "æƒ…å ±é€šä¿¡(Info)": ["9432.T","9433.T","9434.T","9984.T","4689.T","4755.T","9613.T","9602.T","4385.T","6098.T","3659.T","3765.T"],
    "é›»æ©Ÿãƒ»ç²¾å¯†(Elec)": ["8035.T","6857.T","6146.T","6920.T","6758.T","6501.T","6723.T","6981.T","6954.T","7741.T","6702.T","6503.T","6752.T","7735.T","6861.T"],
    "è‡ªå‹•è»Šãƒ»è¼¸é€(Auto)": ["7203.T","7267.T","6902.T","7201.T","7269.T","7270.T","7272.T","9101.T","9104.T","9020.T","9022.T","9005.T"],
    "åŒ»è–¬å“(Pharma)": ["4502.T","4568.T","4519.T","4503.T","4507.T","4523.T","4578.T","4151.T","4528.T","4506.T"],
    "éŠ€è¡Œ(Bank)": ["8306.T","8316.T","8411.T","8308.T","8309.T","7182.T","5831.T","8331.T","8354.T"],
    "é‡‘è(Fin)": ["8591.T","8604.T","8766.T","8725.T","8750.T","8697.T","8630.T","8570.T"],
    "å•†ç¤¾ãƒ»å¸å£²(Trade)": ["8001.T","8031.T","8058.T","8053.T","8002.T","8015.T","3382.T","9983.T","8267.T","2914.T","7453.T","3092.T"], 
    "æ©Ÿæ¢°(Machinery)": ["6301.T","7011.T","7012.T","6367.T","6273.T","6113.T","6473.T","6326.T"],
    "ã‚¨ãƒãƒ«ã‚®ãƒ¼(Energy)": ["1605.T","5020.T","9501.T","3407.T","4005.T"],
    "å»ºè¨­ãƒ»è³‡æ(Const)": ["1925.T","1928.T","1801.T","1802.T","1812.T","5201.T","5332.T"],
    "ç´ æãƒ»åŒ–å­¦(Mat)": ["4063.T","4452.T","4188.T","4901.T","4911.T","4021.T","4631.T","3402.T"],
    "é£Ÿå“(Foods)": ["2801.T","2802.T","2269.T","2502.T","2503.T","2201.T","2002.T"],
    "é›»åŠ›ãƒ»ã‚¬ã‚¹(Util)": ["9501.T","9503.T","9531.T","9532.T"],
    "ä¸å‹•ç”£(RE)": ["8801.T","8802.T","8830.T","3289.T","3003.T","3231.T"],
    "é‰„é‹¼ãƒ»éé‰„(Steel)": ["5401.T","5411.T","5713.T","5406.T","5711.T","5802.T"],
    "å°å£²(Retail)": ["3382.T", "8267.T", "9983.T", "3092.T", "7453.T"], 
    "é‹è¼¸ãƒ»ç‰©æµ(Trans)": ["9101.T", "9104.T", "9020.T", "9021.T", "9022.T"] 
}

MARKETS = {
    "ğŸ‡ºğŸ‡¸ US": {"bench": "SPY", "name": "S&P 500", "sectors": US_SEC, "stocks": US_STOCKS},
    "ğŸ‡¯ğŸ‡µ JP": {"bench": "1306.T", "name": "TOPIX", "sectors": JP_SEC, "stocks": JP_STOCKS},
}

# FULL NAME DB
NAME_DB = {
    "SPY":"S&P500","1306.T":"TOPIX","XLK":"Tech","XLV":"Health","XLF":"Fin","XLC":"Comm","XLY":"ConsDisc","XLP":"Staples","XLI":"Indust","XLE":"Energy","XLB":"Material","XLU":"Utility","XLRE":"RealEst",
    "1626.T":"æƒ…å ±é€šä¿¡","1631.T":"é›»æ©Ÿç²¾å¯†","1621.T":"è‡ªå‹•è»Š","1632.T":"åŒ»è–¬å“","1623.T":"éŠ€è¡Œ","1624.T":"é‡‘èä»–","1622.T":"å•†ç¤¾å°å£²","1630.T":"æ©Ÿæ¢°","1617.T":"é£Ÿå“","1618.T":"ã‚¨ãƒè³‡æº","1619.T":"å»ºè¨­è³‡æ","1620.T":"ç´ æåŒ–å­¦","1625.T":"é›»æ©Ÿç²¾å¯†","1627.T":"é›»åŠ›ã‚¬ã‚¹","1628.T":"é‹è¼¸ç‰©æµ","1629.T":"å•†ç¤¾å¸å£²","1633.T":"ä¸å‹•ç”£",
    "AAPL":"Apple","MSFT":"Microsoft","NVDA":"NVIDIA","GOOGL":"Alphabet","META":"Meta","AMZN":"Amazon","TSLA":"Tesla","AVGO":"Broadcom","ORCL":"Oracle","CRM":"Salesforce","ADBE":"Adobe","AMD":"AMD","QCOM":"Qualcomm","TXN":"Texas","NFLX":"Netflix","DIS":"Disney","CMCSA":"Comcast","TMUS":"T-Mobile","VZ":"Verizon","T":"AT&T",
    "LLY":"Eli Lilly","UNH":"UnitedHealth","JNJ":"J&J","ABBV":"AbbVie","MRK":"Merck","PFE":"Pfizer","JPM":"JPMorgan","BAC":"BofA","WFC":"Wells Fargo","V":"Visa","MA":"Mastercard","GS":"Goldman","MS":"Morgan Stanley","BLK":"BlackRock","C":"Citi","BRK-B":"Berkshire",
    "HD":"Home Depot","MCD":"McDonalds","NKE":"Nike","SBUX":"Starbucks","PG":"P&G","KO":"Coca-Cola","PEP":"PepsiCo","WMT":"Walmart","COST":"Costco","XOM":"Exxon","CVX":"Chevron","GE":"GE Aero","CAT":"Caterpillar","BA":"Boeing","LMT":"Lockheed","RTX":"RTX","DE":"Deere","MMM":"3M",
    "LIN":"Linde","NEE":"NextEra","DUK":"Duke","SO":"Southern","AMT":"Amer Tower","PLD":"Prologis","INTC":"Intel","CSCO":"Cisco","IBM":"IBM","UBER":"Uber","ABNB":"Airbnb","PYPL":"PayPal",
    "8035.T":"æ±äº¬ã‚¨ãƒ¬ã‚¯","6857.T":"ã‚¢ãƒ‰ãƒãƒ³ãƒ†","6146.T":"ãƒ‡ã‚£ã‚¹ã‚³","6920.T":"ãƒ¬ãƒ¼ã‚¶ãƒ¼ãƒ†ã‚¯","6723.T":"ãƒ«ãƒã‚µã‚¹","6758.T":"ã‚½ãƒ‹ãƒ¼G","6501.T":"æ—¥ç«‹","6981.T":"æ‘ç”°è£½","6954.T":"ãƒ•ã‚¡ãƒŠãƒƒã‚¯","7741.T":"HOYA","6702.T":"å¯Œå£«é€š","6503.T":"ä¸‰è±é›»æ©Ÿ","6752.T":"ãƒ‘ãƒŠHD","7735.T":"SCREEN","6861.T":"ã‚­ãƒ¼ã‚¨ãƒ³ã‚¹","6971.T":"äº¬ã‚»ãƒ©","6645.T":"ã‚ªãƒ ãƒ­ãƒ³",
    "9432.T":"NTT","9433.T":"KDDI","9434.T":"ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯","9984.T":"SBG","4689.T":"LINEãƒ¤ãƒ•ãƒ¼","6098.T":"ãƒªã‚¯ãƒ«ãƒ¼ãƒˆ","4755.T":"æ¥½å¤©G","9613.T":"NTTãƒ‡ãƒ¼ã‚¿","2413.T":"ã‚¨ãƒ ã‚¹ãƒªãƒ¼","4385.T":"ãƒ¡ãƒ«ã‚«ãƒª",
    "7203.T":"ãƒˆãƒ¨ã‚¿","7267.T":"ãƒ›ãƒ³ãƒ€","6902.T":"ãƒ‡ãƒ³ã‚½ãƒ¼","7201.T":"æ—¥ç”£","7269.T":"ã‚¹ã‚ºã‚­","7270.T":"SUBARU","7272.T":"ãƒ¤ãƒãƒç™º","9101.T":"æ—¥æœ¬éƒµèˆ¹","9104.T":"å•†èˆ¹ä¸‰äº•","9020.T":"JRæ±æ—¥æœ¬","9022.T":"JRæ±æµ·","9005.T":"æ±æ€¥",
    "8306.T":"ä¸‰è±UFJ","8316.T":"ä¸‰äº•ä½å‹","8411.T":"ã¿ãšã»","8308.T":"ã‚Šããª","8309.T":"ä¸‰äº•ä½å‹ãƒˆãƒ©","7182.T":"ã‚†ã†ã¡ã‚‡","5831.T":"ã—ãšãŠã‹FG","8331.T":"åƒè‘‰éŠ€","8354.T":"ãµããŠã‹FG",
    "8591.T":"ã‚ªãƒªãƒƒã‚¯ã‚¹","8604.T":"é‡æ‘HD","8766.T":"æ±äº¬æµ·ä¸Š","8725.T":"MS&AD","8750.T":"ç¬¬ä¸€ç”Ÿå‘½","8697.T":"æ—¥æœ¬å–å¼•æ‰€","8630.T":"SOMPO","8570.T":"ã‚¤ã‚ªãƒ³FS",
    "8001.T":"ä¼Šè—¤å¿ ","8031.T":"ä¸‰äº•ç‰©ç”£","8058.T":"ä¸‰è±å•†äº‹","8053.T":"ä½å‹å•†äº‹","8002.T":"ä¸¸ç´…","3382.T":"7&i","9983.T":"ãƒ•ã‚¡ã‚¹ãƒˆãƒª","8267.T":"ã‚¤ã‚ªãƒ³","2914.T":"JT",
    "4063.T":"ä¿¡è¶ŠåŒ–å­¦","4452.T":"èŠ±ç‹","4901.T":"å¯Œå£«ãƒ•ã‚¤ãƒ«ãƒ ","4911.T":"è³‡ç”Ÿå ‚","3407.T":"æ—­åŒ–æˆ","5401.T":"æ—¥æœ¬è£½é‰„","5411.T":"JFE","6301.T":"ã‚³ãƒãƒ„","7011.T":"ä¸‰è±é‡å·¥","6367.T":"ãƒ€ã‚¤ã‚­ãƒ³","6273.T":"SMC",
    "1605.T":"INPEX","5020.T":"ENEOS","9501.T":"æ±é›»EP","9503.T":"é–¢é›»","9531.T":"æ±ã‚¬ã‚¹","4502.T":"æ­¦ç”°","4568.T":"ç¬¬ä¸€ä¸‰å…±","4519.T":"ä¸­å¤–","4503.T":"ã‚¢ã‚¹ãƒ†ãƒ©ã‚¹","4507.T":"å¡©é‡ç¾©","4523.T":"ã‚¨ãƒ¼ã‚¶ã‚¤",
    "8801.T":"ä¸‰äº•ä¸","8802.T":"ä¸‰è±åœ°æ‰€","8830.T":"ä½å‹ä¸","4661.T":"OLC","9735.T":"ã‚»ã‚³ãƒ ","4324.T":"é›»é€š","2127.T":"æ—¥æœ¬M&A","6028.T":"ãƒ†ã‚¯ãƒãƒ—ãƒ­","2412.T":"ãƒ™ãƒãƒ•ã‚£ãƒƒãƒˆ","4689.T":"LINEãƒ¤ãƒ•ãƒ¼",
    "6146.T":"ãƒ‡ã‚£ã‚¹ã‚³","6460.T":"ã‚»ã‚¬ã‚µãƒŸãƒ¼","6471.T":"æ—¥æœ¬ç²¾å·¥","6268.T":"ãƒŠãƒ–ãƒ†ã‚¹ã‚³","2801.T":"ã‚­ãƒƒã‚³ãƒ¼ãƒãƒ³","2802.T":"å‘³ã®ç´ ",
    "5711.T":"ä¸‰è±ãƒãƒ†","5713.T":"ä½å‹é‰±","5802.T":"ä½å‹é›»å·¥","5406.T":"ç¥æˆ¸é‹¼","3402.T":"æ±ãƒ¬","4021.T":"æ—¥ç”£åŒ–","4188.T":"ä¸‰è±ã‚±ãƒŸ","4631.T":"DIC","3765.T":"ã‚¬ãƒ³ãƒ›ãƒ¼","3659.T":"ãƒã‚¯ã‚½ãƒ³","2002.T":"æ—¥æ¸…è£½ç²‰"
}

def get_name(t: str) -> str: return NAME_DB.get(t, t)

# ==========================================
# 4. CORE ENGINES
# ==========================================
@st.cache_data(ttl=1800, show_spinner=False)
def fetch_market_data(tickers: Tuple[str, ...], period: str) -> pd.DataFrame:
    tickers = tuple(dict.fromkeys([t for t in tickers if t]))
    frames = []
    chunk = 40 
    for i in range(0, len(tickers), chunk):
        c = tickers[i:i+chunk]
        try:
            r = yf.download(" ".join(c), period=period, interval="1d", group_by="ticker", auto_adjust=True, threads=True, progress=False)
            if not r.empty: frames.append(r)
        except Exception as e:
            log_system_event(f"Fetch Chunk Error: {e}", "WARN")
            continue
    return pd.concat(frames, axis=1) if frames else pd.DataFrame()

def extract_close_prices(df: pd.DataFrame, expected: List[str]) -> pd.DataFrame:
    if df.empty: return pd.DataFrame()
    try:
        if isinstance(df.columns, pd.MultiIndex):
            if "Close" in df.columns.get_level_values(0): close = df.xs("Close", axis=1, level=0)
            elif "Close" in df.columns.get_level_values(1): close = df.xs("Close", axis=1, level=1)
            else: return pd.DataFrame()
        else: return pd.DataFrame()
        close = close.apply(pd.to_numeric, errors="coerce").dropna(how="all")
        cols = [c for c in expected if c in close.columns]
        return close[cols]
    except Exception as e:
        log_system_event(f"Extract Close Error: {e}", "ERROR")
        return pd.DataFrame()

def audit_data_availability(expected: List[str], df: pd.DataFrame, win: int):
    present = [t for t in expected if t in df.columns]
    if not present: return {"ok": False, "list": []}
    
    last_valid = df[present].apply(lambda x: x.last_valid_index())
    mode_date = last_valid.mode().iloc[0] if not last_valid.empty else None
    
    computable = []
    for t in present:
        if last_valid[t] == mode_date and len(df[t].dropna()) >= win + 1:
            computable.append(t)
            
    return {"ok": True, "list": computable, "mode": mode_date, "count": len(computable), "total": len(expected)}

def calc_technical_metrics(s: pd.Series, b: pd.Series, win: int) -> Dict:
    s_clean = s.dropna()
    b_clean = b.dropna()
    
    if len(s_clean) < win + 1 or len(b_clean) < win + 1: return None
    
    s_win = s.ffill().tail(win+1)
    b_win = b.ffill().tail(win+1)
    
    if s_win.isna().iloc[0] or b_win.isna().iloc[0]: return None

    p_ret = (s_win.iloc[-1]/s_win.iloc[0]-1)*100
    b_ret = (b_win.iloc[-1]/b_win.iloc[0]-1)*100
    rs = p_ret - b_ret
    
    half = max(1, win//2)
    p_half = (s_win.iloc[-1]/s_win.iloc[-half-1]-1)*100
    accel = p_half - (p_ret/2)
    dd = abs(((s_win/s_win.cummax()-1)*100).min())
    
    if len(s_clean) >= 252:
        year_high = s_clean.tail(252).max()
    else:
        year_high = s_clean.max()
        
    curr = s_win.iloc[-1]
    high_dist = (curr / year_high - 1) * 100 if year_high > 0 else 0
    
    rets = {}
    s_ffill = s.ffill()
    for l, d in [("1W",5), ("1M",21), ("3M",63), ("12M",252)]:
        if len(s_ffill) > d:
            rets[l] = (s_ffill.iloc[-1] / s_ffill.iloc[-1-d] - 1) * 100
        else:
            rets[l] = np.nan
    
    return {"RS": rs, "Accel": accel, "MaxDD": dd, "Ret": p_ret, "HighDist": high_dist, **rets}

def calculate_regime(bench_series: pd.Series) -> Tuple[str, float]:
    if len(bench_series) < 200: return "Unknown", 0.5
    
    curr = bench_series.iloc[-1]
    ma200 = bench_series.rolling(200).mean().iloc[-1]
    vol20 = bench_series.pct_change().tail(20).std() * np.sqrt(252)
    
    trend = "Bull" if curr > ma200 else "Bear"
    vol_state = "High" if vol20 > 0.15 else "Low" # 15% threshold
    regime = f"{trend} / {vol_state} Vol"
    weight_momentum = 0.6 if trend == "Bull" else 0.3
    return regime, weight_momentum

def calculate_zscore(s: pd.Series) -> pd.Series:
    if s.std() == 0: return pd.Series(0.0, index=s.index)
    return (s - s.mean()) / s.std(ddof=0)

# --- AI & NEWS (ROBUST & SORTED) ---

@st.cache_data(ttl=1800)
def get_news_consolidated(ticker: str, name: str, limit_each: int = 10) -> Tuple[List[dict], str]:
    news_items = []
    context_lines = []

    # Yahoo
    try:
        raw = yf.Ticker(ticker).news or []
        for n in raw[:limit_each]:
            title = n.get("title","")
            link = n.get("link","")
            pub = n.get("providerPublishTime")
            pub = int(pub) if isinstance(pub, (int, float)) else 0
            news_items.append({"title": title, "link": link, "pub": pub, "src": "Yahoo"})
            if title: context_lines.append(f"- {title}")
    except: pass

    # Google RSS
    try:
        q = urllib.parse.quote(f"{name} æ ª")
        url = f"https://news.google.com/rss/search?q={q}&hl=ja&gl=JP&ceid=JP:ja"
        with urllib.request.urlopen(url, timeout=3) as r:
            root = ET.fromstring(r.read())
            for i in root.findall(".//item")[:limit_each]:
                title = i.findtext("title") or ""
                link = i.findtext("link") or ""
                d = i.findtext("pubDate") or ""
                pub = 0
                try:
                    dt = email.utils.parsedate_to_datetime(d)
                    pub = int(dt.timestamp())
                except: pub = 0
                news_items.append({"title": title, "link": link, "pub": pub, "src": "Google"})
                if title: context_lines.append(f"- {title}")
    except: pass

    news_items.sort(key=lambda x: x["pub"], reverse=True)
    context = "\n".join(context_lines[:15]) 
    return news_items, context

@st.cache_data(ttl=3600)
def get_fundamental_data(ticker: str) -> Dict[str, Any]:
    try:
        info = yf.Ticker(ticker).info
        return {
            "PER": info.get("forwardPE", "N/A"),
            "PBR": info.get("priceToBook", "N/A"),
            "PEG": info.get("pegRatio", "N/A"),
            "Target": info.get("targetMeanPrice", "N/A"),
            "Rec": info.get("recommendationKey", "N/A")
        }
    except:
        return {}

def markdown_bold_to_html(text: str) -> str:
    """Convert Markdown bold to HTML highlight"""
    def repl(m):
        inner = m.group(1)
        cls = "highlight-neg" if any(x in inner for x in ["-", "âˆ’", "ãƒã‚¤ãƒŠã‚¹", "ä¸‹è½", "å¼±", "å®‰"]) else "highlight"
        return f"<span class='{cls}'>{inner}</span>"
    
    text = re.sub(r"\*\*(.+?)\*\*", repl, text)
    text = re.sub(r"(ã€ä¸»ãªå¤‰å‹•è¦å› ã€‘)", r"\n\n\1", text)
    return text

def parse_agent_debate(text: str) -> str:
    """Robust Parser for Agent Debate"""
    mapping = {
        "[FUNDAMENTAL]": ("agent-fundamental", "FUNDAMENTAL"),
        "[SENTIMENT]": ("agent-sentiment", "SENTIMENT"),
        "[VALUATION]": ("agent-valuation", "VALUATION"),
        "[SKEPTIC]": ("agent-skeptic", "SKEPTIC"),
        "[RISK]": ("agent-risk", "RISK"),
        "[JUDGE]": ("agent-verdict", "JUDGE"),
    }
    
    clean = text.replace("```html", "").replace("```", "").strip()
    m = re.search(r"\[[A-Z]+\]", clean)
    if m: clean = clean[m.start():]
    parts = re.split(r'(\[[A-Z]+\])', clean)
    
    html = ""
    current_cls = None
    current_label = None
    buffer = ""
    
    def flush():
        nonlocal html, buffer, current_cls, current_label
        if current_cls and current_label and buffer.strip():
            b = re.sub(r"\s*\n+\s*", " ", buffer).strip()
            html += f"<div class='agent-row {current_cls}'><div class='agent-label'>{current_label}</div><div>{b}</div></div>"
        buffer = ""

    for part in parts:
        part = part.strip()
        if not part: continue
        if part in mapping:
            flush()
            current_cls, current_label = mapping[part]
        else:
            buffer += (" " + part)
            
    flush()
    if not html: html = f"<div class='agent-box'>{clean}</div>"
    return html

def build_sector_candidates_context(df: pd.DataFrame, n: int = 6) -> str:
    cand = df.head(n).copy()
    lines = []
    for _, r in cand.iterrows():
        ret = f"{r['Ret']:.1f}" if pd.notna(r['Ret']) else "-"
        lines.append(f"{r['Name']}({r['Ticker']}): Apex {r['Apex']:.2f}, RS {r['RS']:.1f}, Ret {ret}%, 1M {r['1M']:.1f}%, 3M {r['3M']:.1f}%")
    return "\n".join(lines)

@st.cache_data(ttl=3600)
def generate_ai_content(prompt_key: str, context: Dict) -> str:
    if not HAS_LIB or not API_KEY: return "âš ï¸ AI OFFLINE"
    
    models = ["gemini-2.0-flash", "gemini-2.0-flash-lite"]
    p = ""

    if prompt_key == "market":
        p = f"""
æœŸé–“:{context['s_date']}ã€œ{context['e_date']}
å¸‚å ´:{context['market_name']}
ãƒ™ãƒ³ãƒãƒªã‚¿ãƒ¼ãƒ³:{context['ret']:.2f}%
ã‚»ã‚¯ã‚¿ãƒ¼æœ€å¼·:{context['top']} ã‚»ã‚¯ã‚¿ãƒ¼æœ€å¼±:{context['bot']}
ç´ æ(è¦‹å‡ºã—):{context['headlines']}

ã‚¿ã‚¹ã‚¯:ã“ã®æœŸé–“ã®å¸‚å ´æ¦‚æ³ã‚’ã€èª­ã¿æ‰‹ãŒã€Œã“ã‚Œã ã‘ã§å‹•ããŒç´å¾—ã§ãã‚‹ã€ã‚ˆã†ã«å®Œçµã•ã›ã¦æ›¸ã‘ã€‚
è¦ä»¶:
- 450ã€œ650å­—ã€‚æ®µè½ã®é–“ã«ç©ºè¡Œã‚’å…¥ã‚Œãªã„ã€‚
- æ•°å€¤(ãƒ™ãƒ³ãƒãƒªã‚¿ãƒ¼ãƒ³/æœ€å¼·æœ€å¼±)ã¨ç†ç”±(ææ–™)ã‚’å¿…ãšçµã³ã¤ã‘ã‚‹ã€‚
- ç†ç”±ã¯ã€Œä½•ãŒèµ·ããŸâ†’ã©ã®è³‡ç”£/ã‚»ã‚¯ã‚¿ãƒ¼ã«è³‡é‡‘ãŒå‹•ã„ãŸâ†’æŒ‡æ•°ã«+/-å¯„ä¸ã€ã®é †ã§å› æœã‚’æ›¸ãã€‚
- æ–­å®šã—ã™ããšã€ææ–™ãŒå¼±ã„å ´åˆã¯ã€Œå¯èƒ½æ€§ãŒé«˜ã„/ç¤ºå”†ã€ã¨è¡¨ç¾ã—ã¦ã‚ˆã„ãŒã€ç†ç”±ãã®ã‚‚ã®ã¯å¿…ãšæ›¸ãã€‚
- ã€Œãƒ‹ãƒ¥ãƒ¼ã‚¹ã§ã¯ã€ã€ã€Œã€œãŒã‚ã‚Šã¾ã—ãŸã€ç­‰ã®ç„¡é§„ãªå‰ç½®ãã¯ç¦æ­¢ã€‚ã„ããªã‚Šæœ¬é¡Œã‹ã‚‰ã€‚
- é‡è¦ãªä¸Šæ˜‡è¦å› /ãƒ—ãƒ©ã‚¹ææ–™ã¯ **å¤ªå­—** ã§å¼·èª¿ã€‚
- é‡è¦ãªä¸‹è½è¦å› /ãƒªã‚¹ã‚¯ã¯ **å¤ªå­—** ã§å¼·èª¿ã€‚
æœ€å¾Œã«ã€ä¸»ãªå¤‰å‹•è¦å› ã€‘ã¨ã—ã¦3ã€œ6å€‹ã®ç®‡æ¡æ›¸ãã€‚å„è¡Œã¯å¿…ãšã€Œ(+)/(âˆ’)ã€ã§ç¬¦å·ã‚’ä»˜ã‘ã€ä½•ãŒã©ã†åŠ¹ã„ãŸã‹ã‚’å…·ä½“çš„ã«(ä¾‹:é‡‘åˆ©ä¸Šæ˜‡â†’ã‚°ãƒ­ãƒ¼ã‚¹é€†é¢¨â†’ãƒ†ãƒƒã‚¯è»ŸåŒ–(âˆ’))ã€‚
"""
    elif prompt_key == "sector_debate":
        p = f"""
ã‚ãªãŸã¯5åã®å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ(Fundamental, Sentiment, Valuation, Skeptic, Risk)ã€‚
å¯¾è±¡ã‚»ã‚¯ã‚¿ãƒ¼:{context['sec']}
å¯¾è±¡æœŸé–“(è¦‹é€šã—):ä»Šå¾Œ3ãƒ¶æœˆ(çŸ­æœŸ)
æ§‹æˆéŠ˜æŸ„æ•°:{context['count']}
å€™è£œéŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿:
{context.get('candidates','')}

ã‚¿ã‚¹ã‚¯:ã“ã®ã‚»ã‚¯ã‚¿ãƒ¼å†…ã§ã€ŒçŸ­æœŸ(3ãƒ¶æœˆ)ã®æ¨å¥¨ã€ã‚’ä½œã‚‹ã€‚å€‹åˆ¥ä¼æ¥­ã®æ·±æ˜ã‚Šã§ã¯ãªãã€ã‚»ã‚¯ã‚¿ãƒ¼å†…ã®ç›¸å¯¾æ¨å¥¨(ã©ã®ã‚¿ã‚¤ãƒ—/æ¡ä»¶ã®éŠ˜æŸ„ãŒæœ‰åˆ©ã‹ã€ä¸Šä½å€™è£œã¯èª°ã‹)ã‚’çµè«–ã¥ã‘ã‚‹ã€‚
å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯æ”¹è¡Œã›ãš1ãƒ–ãƒ­ãƒƒã‚¯ã§æ„è¦‹ã‚’è¿°ã¹ã‚ˆã€‚

å‡ºåŠ›å½¢å¼(å¿…é ˆ):
[FUNDAMENTAL] 3ãƒ¶æœˆã§åŠ¹ãã‚„ã™ã„æ¥­ç¸¾/éœ€çµ¦/ãƒã‚¯ãƒ­ã®è«–ç‚¹â†’ãƒ—ãƒ©ã‚¹/ãƒã‚¤ãƒŠã‚¹
[SENTIMENT] ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ/ãƒã‚¸ã‚·ãƒ§ãƒ‹ãƒ³ã‚°/ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ•ãƒ­ãƒ¼ã®æ–¹å‘â†’ãƒ—ãƒ©ã‚¹/ãƒã‚¤ãƒŠã‚¹
[VALUATION] ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³è¦³ç‚¹(å‰²å®‰/å‰²é«˜ã§ã¯ãªãã€ŒçŸ­æœŸã®å†è©•ä¾¡ä½™åœ°ã€)â†’ãƒ—ãƒ©ã‚¹/ãƒã‚¤ãƒŠã‚¹
[SKEPTIC] åè«–:ãªãœãã®è¦‹æ–¹ãŒå¤–ã‚Œå¾—ã‚‹ã‹ã€é€†å›è»¢æ¡ä»¶
[RISK] 3ãƒ¶æœˆã§èµ·ãã‚„ã™ã„ãƒªã‚¹ã‚¯(ã‚¤ãƒ™ãƒ³ãƒˆã€é‡‘åˆ©ã€ç‚ºæ›¿ã€è¦åˆ¶ã€æ±ºç®—é›†ä¸­ãªã©)ã¨å›é¿ç­–
[JUDGE] ã‚»ã‚¯ã‚¿ãƒ¼æ¨å¥¨åº¦(å¼·æ°—/ä¸­ç«‹/å¼±æ°—)ã€çŸ­æœŸã§å„ªä½ãªâ€œæ¡ä»¶â€ã€æ³¨ç›®éŠ˜æŸ„ãŒã‚ã‚‹ãªã‚‰æœ€å¤§3ã¤(ç†ç”±ã‚’ä¸€è¡Œãšã¤)
"""
    elif prompt_key == "stock_report":
        fund = context.get("fund", {})
        tech = context.get("tech", {})
        
        snap = f"ç›´è¿‘ãƒªã‚¿ãƒ¼ãƒ³(1M/3M/12M): {tech.get('ret_1m'):.1f}% / {tech.get('ret_3m'):.1f}% / {tech.get('ret_12m'):.1f}%\n"
        snap += f"MaxDD: {tech.get('maxdd'):.1f}%, é«˜å€¤ä¹–é›¢: {tech.get('highdist'):.1f}%\n"
        snap += f"äºˆæƒ³PER: {fund.get('PER')}, PBR: {fund.get('PBR')}, PEG: {fund.get('PEG')}, ç›®æ¨™æ ªä¾¡: {fund.get('Target')}"

        p = f"""
        éŠ˜æŸ„: {context['name']} ({context['ticker']})
        
        0. MARKET SNAPSHOTï¼ˆå¿…é ˆãƒ»ãã®ã¾ã¾å¼•ç”¨ï¼‰:
        {snap}
        
        ãƒ‹ãƒ¥ãƒ¼ã‚¹ææ–™:
        {context.get('news','')}
        
        ä¸Šè¨˜ã«åŸºã¥ãã€ä»¥ä¸‹ã®æ§‹æˆã§ãƒ—ãƒ­å‘ã‘ã‚¢ãƒŠãƒªã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã›ã‚ˆã€‚
        æ–‡ä½“:ã€Œã ãƒ»ã§ã‚ã‚‹ã€èª¿ã€‚æŒ¨æ‹¶ä¸è¦ã€‚ä¸æ˜ãªé …ç›®ã¯ã€Œä¸æ˜ã€ã¨æ›¸ã‹ãšé»™ã£ã¦çœç•¥ã›ã‚ˆã€‚
        
        1. **ä¼æ¥­æ¦‚è¦**: ä½•ã‚’ã—ã¦ã„ã‚‹ä¼šç¤¾ã‹ç°¡æ½”ã«ã€‚
        2. **å®šé‡çš„è©•ä¾¡**: ä¸Šè¨˜ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã®æ•°å€¤ã‚’ç”¨ã„ãŸãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³/ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ è©•ä¾¡ã€‚
        3. **ç›´è¿‘ã®ãƒˆãƒ”ãƒƒã‚¯**: ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‹ã‚‰èª­ã¿å–ã‚Œã‚‹å¥½ææ–™ãƒ»æ‚ªææ–™ã€‚
        4. **ã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹**: å¸‚å ´ã®æœŸå¾…å€¤ã¨ä»Šå¾Œã®æ³¨ç›®ç‚¹ã€‚
        """

    for m in models:
        try:
            model = genai.GenerativeModel(m)
            text = model.generate_content(p).text
            return re.sub(r"\n{2,}", "\n", text).strip()
        except Exception as e:
            if "429" in str(e): time.sleep(1); continue
            
    return "AI Unavailable"

# ==========================================
# 5. MAIN UI LOGIC
# ==========================================
@error_boundary
def main():
    st.markdown("<h1 class='brand'>ALPHALENS</h1>", unsafe_allow_html=True)
    
    # Sidebar
    with st.sidebar:
        st.markdown("### SYSTEM LOGS")
        if st.session_state.system_logs:
            for l in st.session_state.system_logs[-5:]:
                st.markdown(f"<div class='log-box'>{l}</div>", unsafe_allow_html=True)
        if st.button("CLEAR LOGS"): st.session_state.system_logs = []; st.rerun()

    # Header
    c1, c2, c3, c4 = st.columns([1.2, 1, 1.2, 0.6])
    with c1: market_key = st.selectbox("MARKET", list(MARKETS.keys()))
    with c2: lookback_key = st.selectbox("WINDOW", list(LOOKBACKS.keys()), index=1)
    with c3: st.caption(f"FETCH: {FETCH_PERIOD}"); st.progress(100)
    with c4: 
        st.write("")
        sync = st.button("SYNC", type="primary", use_container_width=True)

    if st.session_state.last_market_key != market_key:
        st.session_state.selected_sector = None
        st.session_state.last_market_key = market_key

    m_cfg = MARKETS[market_key]
    win = LOOKBACKS[lookback_key]
    bench = m_cfg["bench"]
    
    # Sync
    core_tickers = [bench] + list(m_cfg["sectors"].values())
    if sync or "core_df" not in st.session_state:
        with st.spinner("SYNCING MARKET DATA..."):
            raw = fetch_market_data(tuple(core_tickers), FETCH_PERIOD)
            st.session_state.core_df = extract_close_prices(raw, core_tickers)
    
    core_df = st.session_state.get("core_df", pd.DataFrame())
    if core_df.empty or len(core_df) < win + 1:
        st.warning("WAITING FOR DATA SYNC...")
        return

    audit = audit_data_availability(core_tickers, core_df, win)
    if bench not in audit["list"]:
        st.error("BENCHMARK MISSING")
        return

    # 1. Market Overview
    b_stats = calc_technical_metrics(core_df[bench], core_df[bench], win)
    if not b_stats:
        st.error("BENCH METRICS FAILED")
        return

    regime, weight_mom = calculate_regime(core_df[bench].dropna())
    
    sec_rows = []
    for s_n, s_t in m_cfg["sectors"].items():
        if s_t in audit["list"]:
            res = calc_technical_metrics(core_df[s_t], core_df[bench], win)
            if res:
                res["Sector"] = s_n
                sec_rows.append(res)
    
    # Guard empty sectors
    if not sec_rows:
        st.warning("SECTOR DATA INSUFFICIENT")
        top_sec, bot_sec = "N/A", "N/A"
        sdf = pd.DataFrame([{"Sector":"N/A","RS":0.0}])
        spread = 0.0
    else:
        sdf = pd.DataFrame(sec_rows).sort_values("RS", ascending=True)
        top_sec, bot_sec = sdf.iloc[-1]["Sector"], sdf.iloc[0]["Sector"]
        spread = sdf.iloc[-1]["RS"] - sdf.iloc[0]["RS"]
    
    # Market AI Summary
    s_date = core_df.index[-win-1].strftime('%Y/%m/%d')
    e_date = core_df.index[-1].strftime('%Y/%m/%d')
    _, market_context = get_news_consolidated(bench, m_cfg["name"])
    
    market_text = generate_ai_content("market", {
        "s_date": s_date, "e_date": e_date, "ret": b_stats["Ret"],
        "top": top_sec, "bot": bot_sec,
        "market_name": m_cfg["name"],
        "headlines": market_context
    })
    
    market_html = markdown_bold_to_html(market_text).replace("\n", "<br>")
    
    st.markdown(f"""
    <div class='market-box'>
    <b>MARKET PULSE ({s_date} - {e_date})</b> | Spread: {spread:.1f}pts | Regime: {regime}<br>
    {market_html}
    </div>
    """, unsafe_allow_html=True)

    # 2. Sector Rotation
    st.subheader(f"SECTOR ROTATION ({s_date} - {e_date})")
    
    if not sdf.empty and "Ret" in sdf.columns:
        top_row = sdf.iloc[-1]
        bot_row = sdf.iloc[0]
        rot_sum = (
            f"ãƒ™ãƒ³ãƒ: <span class='highlight'>{b_stats['Ret']:.2f}%</span> | "
            f"æœ€å¼·: <span class='highlight'>{top_row['Sector']}</span> ({top_row.get('Ret',0):.2f}%) | "
            f"æœ€å¼±: <span class='highlight-neg'>{bot_row['Sector']}</span> ({bot_row.get('Ret',0):.2f}%)"
        )
        st.markdown(f"<div style='margin-bottom:10px; font-size:13px'>{rot_sum}</div>", unsafe_allow_html=True)

    click_sec = None
    sel = st.session_state.get("sector_chart", None)
    try:
        if isinstance(sel, dict) and sel.get("selection", {}).get("points"):
            click_sec = sel["selection"]["points"][0].get("y")
        elif sel and hasattr(sel, "selection") and sel.selection and sel.selection.get("points"):
            click_sec = sel.selection["points"][0].get("y")
    except: pass

    if click_sec and click_sec in m_cfg["sectors"]:
        st.session_state.selected_sector = click_sec

    selected = st.session_state.selected_sector
    colors = ["#333"] * len(sdf)
    if selected and selected in sdf["Sector"].values:
        pos = sdf.index.get_loc(sdf[sdf["Sector"] == selected].index[0])
        colors[pos] = "#00f2fe"

    fig = px.bar(sdf, x="RS", y="Sector", orientation='h', title=f"Relative Strength ({lookback_key})")
    fig.update_traces(marker_color=colors)
    fig.update_layout(height=400, margin=dict(l=0,r=0,t=30,b=0), paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)', font_color='#e0e0e0', font_family="Orbitron")
    
    st.plotly_chart(fig, use_container_width=True, on_select="rerun", key="sector_chart")
    
    st.write("SELECT SECTOR:")
    cols = st.columns(2)
    valid_sectors = set(m_cfg["sectors"].keys())
    
    for i, s in enumerate(m_cfg["sectors"].keys()):
        label = f"âœ… {s}" if s == st.session_state.selected_sector else s
        if cols[i%2].button(label, key=f"btn_{s}", use_container_width=True):
            st.session_state.selected_sector = s
            st.rerun()
            
    if st.session_state.selected_sector not in valid_sectors:
        st.session_state.selected_sector = list(valid_sectors)[0] if valid_sectors else None
        
    target_sector = st.session_state.selected_sector
    
    if target_sector:
        st.caption(f"Current: **{target_sector}** â†’ [Jump to Analysis](#sector_anchor)")

    # 3. Sector Forensic
    st.markdown(f"<div id='sector_anchor'></div>", unsafe_allow_html=True)
    st.divider()
    st.subheader(f"SECTOR FORENSIC: {target_sector}")
    
    stock_list = m_cfg["stocks"].get(target_sector, [])
    if not stock_list:
        st.warning("No stocks mapped.")
        return

    full_list = [bench] + stock_list
    cache_key = f"{market_key}_{target_sector}_{lookback_key}"
    
    if cache_key != st.session_state.get("sec_cache_key") or sync:
        with st.spinner(f"ANALYZING {len(stock_list)} STOCKS..."):
            raw_s = fetch_market_data(tuple(full_list), FETCH_PERIOD)
            st.session_state.sec_df = extract_close_prices(raw_s, full_list)
            st.session_state.sec_cache_key = cache_key
            
    sec_df = st.session_state.sec_df
    s_audit = audit_data_availability(full_list, sec_df, win)
    
    results = []
    for t in [x for x in s_audit["list"] if x != bench]:
        stats = calc_technical_metrics(sec_df[t], sec_df[bench], win)
        if stats:
            stats["Ticker"] = t
            stats["Name"] = get_name(t)
            results.append(stats)
            
    if not results:
        st.warning("NO VALID DATA.")
        return
        
    df = pd.DataFrame(results)
    df["Apex"] = weight_mom * calculate_zscore(df["RS"]) + (0.8 - weight_mom) * calculate_zscore(df["Accel"]) + 0.2 * calculate_zscore(df["Ret"])
    df["Conf"] = 80 + (calculate_zscore(df["Apex"]).abs() * 5).clip(0, 15)
    df = df.sort_values("Apex", ascending=False)
    
    # 4. 5-AGENT SECTOR COUNCIL
    st.markdown("##### ğŸ¦… 5-AGENT SECTOR COUNCIL (Top Picks Strategy)")
    
    cand_ctx = build_sector_candidates_context(df, n=6)
    _, sec_news = get_news_consolidated(m_cfg["sectors"][target_sector], target_sector, limit_each=5)
    
    sec_ai_raw = generate_ai_content("sector_debate", {
        "sec": target_sector,
        "count": len(df),
        "candidates": cand_ctx,
        "top5": ", ".join(df.head(5)["Name"].tolist()),
        "avg_rs": f"{df['RS'].mean():.2f}",
        "news": sec_news
    })
    st.markdown(parse_agent_debate(sec_ai_raw), unsafe_allow_html=True)
    st.caption("EVIDENCE: TOP CANDIDATES")
    st.dataframe(df.head(6)[["Name","Apex","RS","Accel","Ret","1M","HighDist"]], hide_index=True, use_container_width=True)

    # 5. Leaderboard
    st.markdown("##### LEADERBOARD")
    event = st.dataframe(
        df[["Name", "Conf", "Apex", "RS", "Accel", "HighDist", "1W", "1M", "12M"]],
        column_config={
            "Conf": st.column_config.ProgressColumn("Confidence", format="%.0f", min_value=0, max_value=100),
            "Apex": st.column_config.NumberColumn(format="%.2f"),
            "RS": st.column_config.ProgressColumn(format="%.2f%%", min_value=-20, max_value=20),
            "Accel": st.column_config.NumberColumn(format="%.2f"),
            "HighDist": st.column_config.NumberColumn("High%", format="%.1f%%"),
            "1W": st.column_config.NumberColumn(format="%.1f%%"),
            "1M": st.column_config.NumberColumn(format="%.1f%%"),
            "12M": st.column_config.NumberColumn(format="%.1f%%"),
        },
        hide_index=True, use_container_width=True, on_select="rerun", selection_mode="single-row", key="stock_table"
    )
    
    # 6. Deep Dive
    top = df.iloc[0]
    is_default = True
    try:
        if hasattr(event, "selection") and event.selection:
            sel_rows = event.selection.get("rows", [])
            if sel_rows:
                top = df.iloc[sel_rows[0]]
                is_default = False
    except: pass

    st.divider()
    lbl = f"{top['Name']} (Default: Top Ranked)" if is_default else top['Name']
    st.markdown(f"### ğŸ¦… DEEP DIVE: {lbl}")
    
    news_items, news_context = get_news_consolidated(top["Ticker"], top["Name"], limit_each=10)
    fund_data = get_fundamental_data(top["Ticker"])
    
    tech_ctx = {
        "ret_1m": top.get("1M", np.nan), "ret_3m": top.get("3M", np.nan),
        "ret_12m": top.get("12M", np.nan), "maxdd": top.get("MaxDD", np.nan),
        "highdist": top.get("HighDist", np.nan)
    }
    
    report_txt = generate_ai_content("stock_report", {
        "name": top["Name"], "ticker": top["Ticker"],
        "fund": fund_data, "tech": tech_ctx, "news": news_context
    })
    
    nc1, nc2 = st.columns([1.5, 1])
    with nc1:
        st.markdown(f"<div class='report-box'><b>ANALYST REPORT</b><br>{report_txt}</div>", unsafe_allow_html=True)
    with nc2:
        st.caption("INTEGRATED NEWS FEED (Newest â†’ Oldest)")
        for n in news_items[:20]:
            dt = datetime.fromtimestamp(n["pub"]).strftime("%Y/%m/%d %H:%M") if n["pub"] else "N/A"
            st.markdown(f"- {dt} [{n['src']}] [{n['title']}]({n['link']})")

if __name__ == "__main__":
    main()