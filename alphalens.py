import os
import time
import re
import math
import urllib.parse
import urllib.request
import traceback
import xml.etree.ElementTree as ET
import email.utils
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Any, Optional

import numpy as np
import pandas as pd
import plotly.express as px
import streamlit as st
import yfinance as yf

# Import Universe
try:
    import universe
except ImportError:
    st.error("CRITICAL: 'universe.py' not found.")
    st.stop()

# --- UTILS ---
def log_system_event(msg: str, level: str = "INFO", tag: str = "SYS"):
    timestamp = datetime.now().strftime("%H:%M:%S")
    line = f"[{timestamp}] [{level}] [{tag}] {msg}"
    print(line)
    if "system_logs" in st.session_state:
        st.session_state.system_logs.append(line)
        st.session_state.system_logs = st.session_state.system_logs[-300:]

MARKETS = universe.MARKETS
NAME_DB = universe.NAME_DB
LOOKBACKS = {"1W (5d)": 5, "1M (21d)": 21, "3M (63d)": 63, "12M (252d)": 252}
FETCH_PERIOD = "24mo"

@st.cache_data(ttl=86400)
def fetch_name_fallback(ticker: str) -> str:
    try:
        info = yf.Ticker(ticker).info
        n = info.get("shortName") or info.get("longName")
        if n and isinstance(n, str) and len(n) >= 2: return n
    except: pass
    return ticker

def get_name(t: str) -> str:
    n = NAME_DB.get(t)
    if n and n != t: return n
    return fetch_name_fallback(t)

def sfloat(x):
    try: return float(x)
    except: return np.nan

def clamp(x, lo, hi):
    return lo if x < lo else hi if x > hi else x

def sentiment_label(score: int) -> str:
    if score >= 3: return "POS"
    if score <= -3: return "NEG"
    return "NEUT"

def dash(x, fmt="%.1f"):
    if pd.isna(x): return "-"
    try: return fmt % float(x)
    except: return "-"

def pct(x, fmt="%.1f"):
    if pd.isna(x): return "-"
    try: return (fmt % (float(x)*100)) + "%"
    except: return "-"

def outlook_date_slots(days: List[int] = [7, 21, 35, 49, 63, 84]) -> List[str]:
    base = datetime.now().date()
    return [(base + timedelta(days=d)).strftime("%Y/%m/%d") for d in days]

def safe_link_button(label: str, url: str, use_container_width: bool = True):
    if not url:
        st.button(label, disabled=True, use_container_width=use_container_width)
        return
    try:
        fn = getattr(st, "link_button", None)
        if callable(fn):
            fn(label, url, use_container_width=use_container_width)
        else:
            st.markdown(f"- [{label}]({url})")
    except Exception:
        st.markdown(f"- [{label}]({url})")

def build_ir_links(name: str, ticker: str, website: Optional[str], market_key: str) -> Dict[str, str]:
    q_site = urllib.parse.quote(name)
    q_ir = urllib.parse.quote(f"{name} IR")
    if "US" in market_key:
        q_deck = urllib.parse.quote(f"{name} investor presentation earnings pdf")
    else:
        q_deck = urllib.parse.quote(f"{name} æ±ºç®—èª¬æ˜è³‡æ–™ pdf")
            
    official = website if website and website.startswith("http") else f"https://www.google.com/search?q={q_site}+official+site"
    
    return {
        "official": official,
        "ir_search": f"https://www.google.com/search?q={q_ir}",
        "earnings_deck": f"https://www.google.com/search?q={q_deck}",
    }

# --- DATA FETCHING ---
@st.cache_data(ttl=1800)
def fetch_market_data(tickers: Tuple[str, ...], period: str) -> pd.DataFrame:
    tickers = tuple(dict.fromkeys([t for t in tickers if t]))
    frames = []
    chunk = 40 
    for i in range(0, len(tickers), chunk):
        c = tickers[i:i+chunk]
        try:
            r = yf.download(" ".join(c), period=period, interval="1d", group_by="ticker", auto_adjust=True, threads=True, progress=False)
            if not r.empty: frames.append(r)
        except: continue
    return pd.concat(frames, axis=1) if frames else pd.DataFrame()

def extract_close_prices(df: pd.DataFrame, expected: List[str]) -> pd.DataFrame:
    if df.empty: return pd.DataFrame()
    try:
        if isinstance(df.columns, pd.MultiIndex):
            if "Close" in df.columns.get_level_values(0): close = df.xs("Close", axis=1, level=0)
            elif "Close" in df.columns.get_level_values(1): close = df.xs("Close", axis=1, level=1)
            else: return pd.DataFrame()
        else: return pd.DataFrame()
        close = close.apply(pd.to_numeric, errors="coerce").dropna(how="all")
        return close[[c for c in expected if c in close.columns]]
    except: return pd.DataFrame()

def calc_technical_metrics(s: pd.Series, b: pd.Series, win: int) -> Dict:
    s_clean, b_clean = s.dropna(), b.dropna()
    if len(s_clean) < win + 1 or len(b_clean) < win + 1: return None
    s_win, b_win = s.ffill().tail(win+1), b.ffill().tail(win+1)
    if s_win.isna().iloc[0] or b_win.isna().iloc[0]: return None

    p_ret = (s_win.iloc[-1]/s_win.iloc[0]-1)*100
    b_ret = (b_win.iloc[-1]/b_win.iloc[0]-1)*100
    rs = p_ret - b_ret
    
    half = max(1, win//2)
    p_half = (s_win.iloc[-1]/s_win.iloc[-half-1]-1)*100
    accel = p_half - (p_ret/2)
    dd = abs(((s_win/s_win.cummax()-1)*100).min())
    year_high = s_clean.tail(252).max() if len(s_clean) >= 252 else s_clean.max()
    high_dist = (s_win.iloc[-1] / year_high - 1) * 100 if year_high > 0 else 0
    
    rets = {}
    s_ffill = s.ffill()
    for l, d in [("1W",5), ("1M",21), ("3M",63), ("12M",252)]:
        if len(s_ffill) > d: rets[l] = (s_ffill.iloc[-1] / s_ffill.iloc[-1-d] - 1) * 100
        else: rets[l] = np.nan
    
    return {"RS": rs, "Accel": accel, "MaxDD": dd, "Ret": p_ret, "HighDist": high_dist, **rets}

def calculate_regime(bench_series: pd.Series) -> Tuple[str, float]:
    if len(bench_series) < 200: return "Unknown", 0.5
    curr = bench_series.iloc[-1]
    ma200 = bench_series.rolling(200).mean().iloc[-1]
    trend = "Bull" if curr > ma200 else "Bear"
    return trend, 0.6 if trend == "Bull" else 0.3

def audit_data_availability(expected: List[str], df: pd.DataFrame, win: int):
    present = [t for t in expected if t in df.columns]
    if not present: return {"ok": False, "list": []}
    last = df[present].apply(lambda x: x.last_valid_index())
    mode = last.mode().iloc[0] if not last.mode().empty else None
    computable = [t for t in present if last[t] == mode and len(df[t].dropna()) >= win + 1]
    return {"ok": True, "list": computable, "mode": mode, "count": len(computable), "total": len(expected)}

def calculate_zscore(s: pd.Series) -> pd.Series:
    if s.std() == 0: return pd.Series(0.0, index=s.index)
    return (s - s.mean()) / s.std(ddof=0)

def price_action_pack(price: pd.Series) -> Dict[str, float]:
    p = price.dropna()
    if len(p) < 60: return {}
    out = {}
    out["Last"] = float(p.iloc[-1])
    try:
        out["1D"] = float((p.iloc[-1] / p.iloc[-2] - 1) * 100) if len(p) >= 2 else np.nan
        out["1W"] = float((p.iloc[-1] / p.iloc[-6] - 1) * 100) if len(p) >= 6 else np.nan
        out["1M"] = float((p.iloc[-1] / p.iloc[-22] - 1) * 100) if len(p) >= 22 else np.nan
        out["3M"] = float((p.iloc[-1] / p.iloc[-64] - 1) * 100) if len(p) >= 64 else np.nan
        ma200 = p.rolling(200).mean().iloc[-1] if len(p) >= 200 else np.nan
        out["200DMA_Dist"] = float((p.iloc[-1] / ma200 - 1) * 100) if pd.notna(ma200) and ma200 != 0 else np.nan
        dd = (p / p.cummax() - 1) * 100
        out["MaxDD_6M"] = float(dd.tail(126).min()) if len(dd) >= 126 else float(dd.min())
    except: pass
    return out

# --- FUNDAMENTALS ---
@st.cache_data(ttl=3600)
def fetch_fundamentals_batch(tickers: List[str]) -> pd.DataFrame:
    data = []
    def get_info(t):
        try:
            i = yf.Ticker(t).info
            pe = i.get("trailingPE", np.nan)
            if pe is not None and pe < 0: pe = np.nan
            pbr = i.get("priceToBook", np.nan)
            if pbr is not None and pbr < 0: pbr = np.nan
            return {
                "Ticker": t, "MCap": i.get("marketCap", 0),
                "PER": pe, "PBR": pbr, "FwdPE": i.get("forwardPE", np.nan),
                "ROE": i.get("returnOnEquity", np.nan),
                "OpMargin": i.get("operatingMargins", np.nan),
                "RevGrow": i.get("revenueGrowth", np.nan),
                "Beta": i.get("beta", np.nan)
            }
        except: return {"Ticker": t, "MCap": 0}
    with ThreadPoolExecutor(max_workers=10) as executor:
        data = list(executor.map(get_info, tickers))
    return pd.DataFrame(data).set_index("Ticker")

@st.cache_data(ttl=3600)
def get_fundamental_data(ticker: str) -> Dict[str, Any]:
    try:
        i = yf.Ticker(ticker).info
        pe = i.get("trailingPE", np.nan)
        if isinstance(pe, (int, float)) and pe < 0: pe = np.nan
        pbr = i.get("priceToBook", np.nan)
        if isinstance(pbr, (int, float)) and pbr < 0: pbr = np.nan
        
        return {
            "MCap": i.get("marketCap", 0), "PER": pe, "FwdPE": i.get("forwardPE", np.nan),
            "PBR": pbr, "PEG": i.get("pegRatio", np.nan), "Target": i.get("targetMeanPrice", np.nan),
            "Rec": i.get("recommendationKey", "N/A"), "Website": i.get("website", None)
        }
    except: return {"PRICE": np.nan, "MCap": np.nan, "PER": np.nan, "FwdPE": np.nan, "PBR": np.nan, "PEG": np.nan}

def pick_fund_row(cand_fund: pd.DataFrame, ticker: str) -> Dict[str, Any]:
    try:
        if cand_fund is None or cand_fund.empty: return {}
        m = cand_fund[cand_fund["Ticker"] == ticker]
        if m.empty: return {}
        return m.iloc[0].to_dict()
    except: return {}

@st.cache_data(ttl=3600)
def fetch_earnings_dates(ticker: str) -> Dict[str,str]:
    out = {}
    try:
        cal = yf.Ticker(ticker).calendar
        if cal is not None:
            if isinstance(cal, dict) and 'Earnings Date' in cal:
                out["EarningsDate"] = str(cal['Earnings Date'][0])
            elif isinstance(cal, pd.DataFrame):
                 for k in ["Earnings Date", "EarningsDate"]:
                    if k in cal.index:
                        v = cal.loc[k].values
                        out["EarningsDate"] = ", ".join([str(x)[:10] for x in v if str(x) != "nan"])
    except: pass
    return out

# --- AI & TEXT ---
API_KEY = st.secrets.get("GEMINI_API_KEY") or st.secrets.get("GOOGLE_API_KEY") or os.getenv("GOOGLE_API_KEY")
try:
    import google.generativeai as genai
    HAS_LIB = True
    if API_KEY: genai.configure(api_key=API_KEY)
except: HAS_LIB = False

def clean_ai_text(text: str) -> str:
    text = text.replace("```text", "").replace("```", "")
    text = text.replace("**", "").replace('"', "").replace("'", "")
    text = re.sub(r"(?m)^\s*text\s*$", "", text)
    text = re.sub(r"(?m)^\s*#{2,}\s*", "", text)
    text = re.sub(r"(?im)^\s*(agent|ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ)\s*[A-E0-9]+[:ï¼š]\s*", "", text)
    # strip polite / meta preambles
    text = re.sub(r"(?m)^\s*(ã¯ã„ã€)?\s*æ‰¿çŸ¥(ã„ãŸã—ã¾ã—ãŸ|ã—ã¾ã—ãŸ)ã€‚?.*$\n?", "", text)
    text = re.sub(r"(?m)^\s*ä»¥ä¸‹ã«(.*)ä½œæˆ(ã™ã‚‹|ã—ã¾ã™)ã€‚?.*$\n?", "", text)
    text = re.sub(r"(?m)^\s*ã”ä¾é ¼(.*)ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚?.*$\n?", "", text)
    bad = ["ä¸æ˜", "ã‚ã‹ã‚‰ãªã„", "åˆ†ã‹ã‚‰ãªã„", "unknown"]
    for w in bad: text = re.sub(rf"(?m)^.*{re.escape(w)}.*$\n?", "", text)
    return re.sub(r"\n{2,}", "\n", text).strip()

def force_nonempty_outlook_market(text: str, trend: str, ret: float, spread: float, market_key: str) -> str:
    m = re.search(r"ã€ä»Šå¾Œ3ãƒ¶æœˆ[^ã€‘]*ã€‘\n?(.*)", text, flags=re.DOTALL)
    body = m.group(1).strip() if m else ""
    if len(re.sub(r"[\s\(\)ãƒ»\-âˆ’\n]", "", body)) >= 30: return text

    slots = outlook_date_slots()
    if "US" in market_key:
        events = [
            f"FOMC({slots[1]})â†’é‡‘åˆ©ç¹”ã‚Šè¾¼ã¿å†è¨ˆç®—ã§ãƒã‚¤PERã®å¤‰å‹•ãŒå¢—å¹…",
            f"CPI/PCE({slots[0]})â†’ã‚¤ãƒ³ãƒ•ãƒ¬éˆåŒ–ãªã‚‰ãƒªã‚¹ã‚¯ã‚ªãƒ³ã€å†åŠ é€Ÿãªã‚‰ãƒªã‚¹ã‚¯ã‚ªãƒ•",
            f"é›‡ç”¨çµ±è¨ˆ({slots[0]})â†’è³ƒé‡‘ã®ç²˜ç€æ€§ãŒé•·æœŸé‡‘åˆ©ã‚’å·¦å³",
            f"ä¸»è¦æ±ºç®—({slots[2]})â†’ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã§æŒ‡æ•°å¯„ä¸ãŒé›†ä¸­ã—ã‚„ã™ã„",
            f"ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆ/æµå‹•æ€§({slots[3]})â†’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰æ‹¡å¤§ã¯æ ªã®ä¸Šå€¤æŠ‘åˆ¶",
            f"éœ€çµ¦ã‚¤ãƒ™ãƒ³ãƒˆ({slots[4]})â†’ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ»ãƒªãƒãƒ©ãƒ³ã‚¹ã§çŸ­æœŸã‚¹ãƒ‘ã‚¤ã‚¯"
        ]
    else:
        events = [
            f"æ—¥éŠ€ä¼šåˆ({slots[1]})â†’é‡‘åˆ©ã¨å††ãŒåŒæ™‚ã«å‹•ãã€å¤–éœ€/å†…éœ€ã®å„ªåŠ£ãŒåè»¢ã—ã‚„ã™ã„",
            f"ç±³é‡‘åˆ©ãƒ»å††ç›¸å ´({slots[0]})â†’è¼¸å‡ºãƒ»ã‚¤ãƒ³ãƒã‚¦ãƒ³ãƒ‰ã®æ„Ÿå¿œåº¦ãŒé«˜ã„",
            f"ä¸»è¦æ±ºç®—({slots[2]})â†’é€šæœŸè¦‹é€šã—ä¿®æ­£ã¨æ ªä¸»é‚„å…ƒãŒéœ€çµ¦ã‚’æ±ºã‚ã‚‹",
            f"æŒ‡æ•°ãƒªãƒãƒ©ãƒ³ã‚¹({slots[3]})â†’éœ€çµ¦æ­ªã¿ã§çŸ­æœŸå¤‰å‹•ãŒå‡ºã‚„ã™ã„",
            f"è³ƒä¸Šã’ãƒ»ç‰©ä¾¡({slots[4]})â†’å®Ÿè³ªè³ƒé‡‘ã§æ¶ˆè²»é–¢é€£ã®ç›¸å¯¾ãŒå‹•ã",
            f"æµ·å¤–æŠ•è³‡å®¶ãƒ•ãƒ­ãƒ¼({slots[5]})â†’è³‡é‡‘æµå…¥ã®ç¶™ç¶šæ€§ãŒåœ°åˆã„ã‚’è¦å®š"
        ]

    fallback = "ã€ä»Šå¾Œ3ãƒ¶æœˆã®ã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹è¦‹é€šã—ã€‘\n" + "\n".join([f"ãƒ»{e}" for e in events]) + \
               f"\nãƒ»å¼·æ°—æ¡ä»¶ï¼šã‚¤ãƒ³ãƒ•ãƒ¬é®é™åŒ–ï¼‹æ¥­ç¸¾ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ä¸ŠæŒ¯ã‚Œï¼ˆåŸºèª¿:{trend}ï¼‰\nãƒ»å¼±æ°—æ¡ä»¶ï¼šé‡‘åˆ©å†ä¸Šæ˜‡ï¼‹ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ä¸‹æ–¹ä¿®æ­£ã®é€£é–"

    if "ã€ä»Šå¾Œ3ãƒ¶æœˆ" in text:
        text = re.sub(r"ã€ä»Šå¾Œ3ãƒ¶æœˆ[^ã€‘]*ã€‘.*", fallback, text, flags=re.DOTALL)
    else:
        text = text.rstrip() + "\n" + fallback
    return text

def enforce_market_format(text: str) -> str:
    """Normalize Market Pulse text to required sections; resilient to messy LLM outputs."""
    if not isinstance(text, str):
        text = str(text)

    text = text.replace("\r\n", "\n").replace("\r", "\n").strip()

    # Remove common assistant boilerplate/meta
    text = re.sub(r"(?im)^\s*(ã¯ã„ã€)?\s*æ‰¿çŸ¥(ã„ãŸ)?ã—ã¾ã—ãŸ[ã€‚!ï¼]*.*\n+", "", text)
    text = re.sub(r"(?im)^\s*ä»¥ä¸‹ã«.*(ä½œæˆ|ç”Ÿæˆ).*(ã—ã¾ã™|ã„ãŸã—ã¾ã™)[ã€‚!ï¼]*\s*$", "", text)

    # Remove unwanted date suffix right after the outlook header

    # Replace placeholder event names (EventA/B/C...) with meaningful labels (best-effort)
    def _event_label(reason: str) -> str:
        r = reason
        if re.search(r"(CPI|ã‚¤ãƒ³ãƒ•ãƒ¬|ç‰©ä¾¡|PCE)", r, re.I): return "Inflation data"
        if re.search(r"(é›‡ç”¨|Payroll|å¤±æ¥­|NFP)", r, re.I): return "Jobs data"
        if re.search(r"(FOMC|FRB|Fed|åˆ©ä¸Šã’|åˆ©ä¸‹ã’|é‡‘èæ”¿ç­–)", r, re.I): return "Central bank"
        if re.search(r"(æ±ºç®—|earnings)", r, re.I): return "Earnings"
        if re.search(r"(åœ°æ”¿å­¦|ä¸­æ±|å°æ¹¾|ã‚¦ã‚¯ãƒ©ã‚¤ãƒŠ|ç´›äº‰)", r, re.I): return "Geopolitics"
        if re.search(r"(é‡‘åˆ©|é•·æœŸé‡‘åˆ©|åˆ©å›ã‚Š|bond)", r, re.I): return "Rates"
        if re.search(r"(åŸæ²¹|OPEC)", r, re.I): return "Oil supply"
        return "Macro catalyst"

    def _rename_event_lines(t: str) -> str:
        # Pattern: - ã‚¤ãƒ™ãƒ³ãƒˆA(2026-03-01)â†’...â†’ç†ç”±
        out_lines = []
        for ln in t.splitlines():
            m = re.match(r"^\s*-\s*(ã‚¤ãƒ™ãƒ³ãƒˆ|Event)\s*([A-F])\s*\(([^)]+)\)\s*â†’\s*(.*)$", ln)
            if m:
                date = m.group(3)
                rest = m.group(4)
                label = _event_label(rest)
                ln = f"- {label} ({date})â†’{rest}"
            out_lines.append(ln)
        return "\n".join(out_lines)

    text = re.sub(r"(ã€ä»Šå¾Œ3ãƒ¶æœˆ[^ã€‘]*ã€‘)\s*\(\d{4}[-/]\d{2}[-/]\d{2}\)", r"\1", text)
    text = re.sub(r"(ã€ä»Šå¾Œ3ãƒ¶æœˆ[^ã€‘]*ã€‘)\s*\d{4}[-/]\d{2}[-/]\d{2}", r"\1", text)

    # Ensure required headers exist
    if "ã€å¸‚å ´æ¦‚æ³ã€‘" not in text:
        text = "ã€å¸‚å ´æ¦‚æ³ã€‘\n" + text

    if "ã€ä¸»ãªå¤‰å‹•è¦å› ã€‘" not in text:
        text += "\n\nã€ä¸»ãªå¤‰å‹•è¦å› ã€‘\n(+) ä¸Šæ˜‡è¦å› :\n(-) ä¸‹è½è¦å› :"

    if "ã€ä»Šå¾Œ3ãƒ¶æœˆ" not in text:
        text += "\n\nã€ä»Šå¾Œ3ãƒ¶æœˆã®ã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹è¦‹é€šã—ã€‘\n"

    text = _rename_event_lines(text)

    return text

def enforce_index_naming(text: str, index_label: str) -> str:
    if not index_label:
        return text
    # Replace vague wording with explicit index label
    text = re.sub(r"å¸‚å ´å¹³å‡(ãƒªã‚¿ãƒ¼ãƒ³)?", index_label, text)
    text = re.sub(r"æŒ‡æ•°(?:å…¨ä½“)?", index_label, text)
    # Ensure the index label appears at least once in the market overview
    if index_label not in text and "ã€å¸‚å ´æ¦‚æ³ã€‘" in text:
        text = re.sub(r"(ã€å¸‚å ´æ¦‚æ³ã€‘\n?)", rf"\1{index_label}ã‚’åŸºæº–ã«è¨˜è¿°ã™ã‚‹ã€‚\n", text, count=1)
    return text

def group_plus_minus_blocks(text: str) -> str:
    # Extract the block
    m = re.search(r"ã€ä¸»ãªå¤‰å‹•è¦å› ã€‘\n?(.*?)(?=\nã€|\Z)", text, flags=re.DOTALL)
    if not m:
        return text
    block = m.group(1).strip()
    lines = [l.strip() for l in block.splitlines() if l.strip()]

    # remove fake headings that often get bulletized
    heading_trash = {"ä¸Šæ˜‡è¦å› :", "ä¸‹è½è¦å› :", "(+) ä¸Šæ˜‡è¦å› :", "(-) ä¸‹è½è¦å› :", "ï¼ˆ+ï¼‰ä¸Šæ˜‡è¦å› :", "ï¼ˆâˆ’ï¼‰ä¸‹è½è¦å› :"}
    cleaned = []
    for l in lines:
        l2 = l.lstrip("-ãƒ» ").strip()
        if l2 in heading_trash:
            continue
        # remove "ã‚¤ãƒ™ãƒ³ãƒˆA" etc accidentally placed here
        if l2.startswith("3)") or "ä»Šå¾Œ3ãƒ¶æœˆ" in l2:
            continue
        cleaned.append(l)

    pos, neg, oth = [], [], []
    pos_kw = ["ä¸Šæ–¹ä¿®æ­£","å¢—ç›Š","å¥½èª¿","å›å¾©","ä½ä¸‹","éˆåŒ–","åˆ©ä¸‹ã’","åˆ©å›ã‚Šä½ä¸‹","é‡‘åˆ©ä½ä¸‹","ç·©å’Œ","è²·ã„","è³‡é‡‘æµå…¥","å¼·ã„","ä¸Šæ˜‡","æ”¹å–„","å‰²å®‰","è‡ªç¤¾æ ªè²·ã„","éœ€è¦å¢—","å—æ³¨å¢—","ã‚¤ãƒ³ãƒ•ãƒ¬ä½ä¸‹","ã‚½ãƒ•ãƒˆã‚¤ãƒ³ãƒ•ãƒ¬","æ™¯æ°—å¾Œé€€æ‡¸å¿µå¾Œé€€"]
    neg_kw = ["ä¸‹æ–¹ä¿®æ­£","æ¸›ç›Š","æ‚ªåŒ–","å¤±é€Ÿ","å†åŠ é€Ÿ","åˆ©ä¸Šã’","å¼•ãç· ã‚","ã‚¿ã‚«æ´¾","å£²ã‚Š","è³‡é‡‘æµå‡º","ä¸‹è½","è­¦æˆ’","é«˜æ­¢ã¾ã‚Š","ãƒªã‚¹ã‚¯","åœ°æ”¿å­¦","é•·æœŸé‡‘åˆ©ä¸Šæ˜‡","é‡‘åˆ©ä¸Šæ˜‡","åˆ©å›ã‚Šä¸Šæ˜‡","ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£","æ‡¸å¿µ","è­¦å‘Šã‚·ã‚°ãƒŠãƒ«","ãƒ†ãƒƒã‚¯å£²ã‚Š","ãƒªãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°"]

    for l in cleaned:
        raw = l.lstrip("-ãƒ» ").strip()
        # explicit sign markers
        if raw.startswith("(+)") or raw.startswith("ï¼‹") or raw.startswith("+"):
            pos.append(raw.lstrip("()+ï¼‹+ ").strip())
            continue
        if raw.startswith("(-)") or raw.startswith("âˆ’") or raw.startswith("-"):
            neg.append(raw.lstrip("()-âˆ’- ").strip())
            continue
        # keyword routing
        score = 0
        if any(k in raw for k in pos_kw): score += 1
        if any(k in raw for k in neg_kw): score -= 1
        if score > 0:
            pos.append(raw)
        elif score < 0:
            neg.append(raw)
        else:
            oth.append(raw)

    # Build normalized section
    def bullets(arr):
        return "\n".join([f"- {x}" for x in arr[:6]]) if arr else "- ï¼ˆè©²å½“ææ–™ã‚’æŠ½å‡ºã§ããšï¼‰"
    out = "ã€ä¸»ãªå¤‰å‹•è¦å› ã€‘\n(+) ä¸Šæ˜‡è¦å› :\n" + bullets(pos) + "\n(âˆ’) ä¸‹è½è¦å› :\n" + bullets(neg)
    if oth:
        out += "\n(è£œè¶³):\n" + "\n".join([f"- {x}" for x in oth[:6]])
    # Replace original block
    return text[:m.start()] + out + text[m.end():]
def enforce_da_dearu_soft(text: str) -> str:
    text = re.sub(r"ã§ã™ã€‚", "ã ã€‚", text)
    text = re.sub(r"ã§ã™$", "ã ", text, flags=re.MULTILINE)
    text = re.sub(r"ã¾ã™ã€‚", "ã™ã‚‹ã€‚", text)
    text = re.sub(r"ã¾ã™$", "ã™ã‚‹", text, flags=re.MULTILINE)
    return text

def market_to_html(text: str) -> str:
    text = re.sub(r"(^\(\+\s*\).*$)", r"<span class='hl-pos'>\1</span>", text, flags=re.MULTILINE)
    text = re.sub(r"(^\(\-\s*\).*$)", r"<span class='hl-neg'>\1</span>", text, flags=re.MULTILINE)
    return text.replace("\n", "<br>")

@st.cache_data(ttl=1800)
def get_news_consolidated(ticker: str, name: str, market_key: str, limit_each: int = 10) -> Tuple[List[dict], str, int, Dict[str,int]]:
    news_items, context_lines = [], []
    pos_words = ["å¢—ç›Š", "æœ€é«˜å€¤", "å¥½æ„Ÿ", "ä¸Šæ˜‡", "è‡ªç¤¾æ ªè²·ã„", "ä¸Šæ–¹ä¿®æ­£", "æ€¥é¨°", "beat", "high", "jump", "record"]
    neg_words = ["æ¸›ç›Š", "å®‰å€¤", "å«Œæ°—", "ä¸‹è½", "ä¸‹æ–¹ä¿®æ­£", "æ€¥è½", "èµ¤å­—", "miss", "low", "drop", "warn"]
    sentiment_score = 0
    meta = {"yahoo":0, "google":0, "pos":0, "neg":0}

    # Yahoo
    try:
        raw = yf.Ticker(ticker).news or []
        for n in raw[:limit_each]:
            t, l, p = n.get("title",""), n.get("link",""), n.get("providerPublishTime",0)
            news_items.append({"title":t, "link":l, "pub":p, "src":"Yahoo"})
            if t:
                meta["yahoo"] += 1
                dt = datetime.fromtimestamp(p).strftime("%Y/%m/%d") if p else "-"
                weight = 2 if (time.time() - p) < 172800 else 1
                context_lines.append(f"- [Yahoo {dt}] {t}")
                if any(w in t for w in pos_words): sentiment_score += 1*weight; meta["pos"] += 1
                if any(w in t for w in neg_words): sentiment_score -= 1*weight; meta["neg"] += 1
    except: pass

    # Google
    try:
        if "US" in market_key:
            hl, gl, ceid = "en", "US", "US:en"
            q = urllib.parse.quote(f"{name} stock")
        else:
            hl, gl, ceid = "ja", "JP", "JP:ja"
            q = urllib.parse.quote(f"{name} æ ª")
            
        url = f"https://news.google.com/rss/search?q={q}&hl={hl}&gl={gl}&ceid={ceid}"
        with urllib.request.urlopen(url, timeout=3) as r:
            root = ET.fromstring(r.read())
            for i in root.findall(".//item")[:limit_each]:
                t, l, d = i.findtext("title"), i.findtext("link"), i.findtext("pubDate")
                try: pub = int(email.utils.parsedate_to_datetime(d).timestamp())
                except: pub = 0
                news_items.append({"title":t, "link":l, "pub":pub, "src":"Google"})
                if t:
                    meta["google"] += 1
                    dt = datetime.fromtimestamp(pub).strftime("%Y/%m/%d") if pub else "-"
                    weight = 2 if (time.time() - pub) < 172800 else 1
                    context_lines.append(f"- [Google {dt}] {t}")
                    if any(w in t for w in pos_words): sentiment_score += 1*weight; meta["pos"] += 1
                    if any(w in t for w in neg_words): sentiment_score -= 1*weight; meta["neg"] += 1
    except: pass

    # Free public RSS feeds (fallback / enrichment). English-only is OK.
    try:
        rss_sources = [
            ("Reuters Markets", "https://feeds.reuters.com/reuters/marketsNews"),
            ("Reuters Business", "https://feeds.reuters.com/reuters/businessNews"),
            ("MarketWatch", "https://feeds.marketwatch.com/marketwatch/topstories/"),
            ("CNBC", "https://www.cnbc.com/id/100003114/device/rss/rss.html"),
            ("BBC Business", "https://feeds.bbci.co.uk/news/business/rss.xml"),
        ]
        for src, url2 in rss_sources:
            try:
                with urllib.request.urlopen(url2, timeout=3) as r:
                    root = ET.fromstring(r.read())
                    for it in root.findall('.//item')[: max(3, limit_each//3) ]:
                        t2, l2, d2 = it.findtext('title'), it.findtext('link'), it.findtext('pubDate')
                        try: pub2 = int(email.utils.parsedate_to_datetime(d2).timestamp())
                        except: pub2 = 0
                        if not t2: continue
                        news_items.append({"title": t2, "link": l2, "pub": pub2, "src": src})
                        dt2 = datetime.fromtimestamp(pub2).strftime('%Y/%m/%d') if pub2 else "-"
                        weight = 2 if (pub2 and (time.time() - pub2) < 172800) else 1
                        context_lines.append(f"- [{src} {dt2}] {t2}")
                        if any(w in t2 for w in pos_words): sentiment_score += 1*weight; meta["pos"] += 1
                        if any(w in t2 for w in neg_words): sentiment_score -= 1*weight; meta["neg"] += 1
            except Exception:
                pass
    except Exception:
        pass


    news_items.sort(key=lambda x: x["pub"], reverse=True)
    return news_items, "\n".join(context_lines[:15]), sentiment_score, meta

def temporal_sanity_flags(text: str) -> List[str]:
    bad = ["å¹´æœ«å¹´å§‹", "ã‚¯ãƒªã‚¹ãƒã‚¹", "å¤ä¼‘ã¿", "ãŠç›†", "æ¥å¹´", "æ˜¨å¹´æœ«"]
    return [w for w in bad if w in text]

def sector_debate_quality_ok(text: str) -> bool:
    needed = ["[SECTOR_OUTLOOK]", "[FUNDAMENTAL]", "[SENTIMENT]", "[VALUATION]", "[SKEPTIC]", "[RISK]", "[JUDGE]"]
    if any(t not in text for t in needed): return False
    min_chars = {
        "[SECTOR_OUTLOOK]": 220, "[FUNDAMENTAL]": 260, "[SENTIMENT]": 260,
        "[VALUATION]": 220, "[SKEPTIC]": 220, "[RISK]": 220, "[JUDGE]": 520,
    }
    for k, mn in min_chars.items():
        m = re.search(re.escape(k) + r"(.*?)(?=\n\[[A-Z_]+\]|\Z)", text, flags=re.DOTALL)
        if not m or len(re.sub(r"\s+", "", m.group(1))) < mn: return False
    if re.search(r"(?im)(ç§ã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ|åƒ•ã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ|ä¿ºã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ|ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ[A-E])", text): return False
    return True

@st.cache_data(ttl=3600)
def generate_ai_content(prompt_key: str, context: Dict) -> str:
    if not HAS_LIB or not API_KEY: return "AI OFFLINE"
    
    models = ["gemini-2.0-flash", "gemini-2.0-flash-lite"]
    p = ""
    market_n = context.get('market_name', 'Global')
    today_str = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')
    # slot_line: candidate dates for the next 3 months (used in market prompt)
    slot_line = context.get("slot_line")
    if not slot_line:
        # fallback: today + 7d steps (within 90 days)
        base = datetime.now().date()
        slots = [base + timedelta(days=d) for d in [7,14,21,28,35,42,49,56,63,70,77,84]]
        slot_line = ", ".join([s.strftime("%Y-%m-%d") for s in slots])
    
    
    if prompt_key == "market":
        p = f"""
        ç¾åœ¨: {today_str} (ã“ã®æ—¥ä»˜ã‚’åŸºæº–ã«åˆ†æã›ã‚ˆ)
        å¯¾è±¡å¸‚å ´: {market_n} (ã“ã‚Œä»¥å¤–ã®å¸‚å ´ã®è©±ã¯ç¦æ­¢)
        å¯¾è±¡æŒ‡æ•°: {context.get('index_label','')}ï¼ˆã“ã®æŒ‡æ•°åã‚’å¿…ãšæœ¬æ–‡ã«æ˜è¨˜ã›ã‚ˆã€‚ã€Œå¸‚å ´å¹³å‡ã€ã¨ã„ã†èªã¯ç¦æ­¢ï¼‰
        æœŸé–“:{context['s_date']}ã€œ{context['e_date']}
        å¯¾è±¡æŒ‡æ•°ãƒªã‚¿ãƒ¼ãƒ³:{context['ret']:.2f}%
        æœ€å¼·:{context['top']} æœ€å¼±:{context['bot']}
        ãƒ‹ãƒ¥ãƒ¼ã‚¹:{context['headlines']}
        Nonce:{context.get('nonce',0)}
        
        ã“ã®æœŸé–“ã®{market_n}å¸‚å ´æ¦‚æ³ã‚’ãƒ—ãƒ­å‘ã‘ã«450-650å­—ã§è¨˜è¿°ã›ã‚ˆã€‚
        ç¦æ­¢: ã€Œå¸‚å ´å¹³å‡ã€ã€Œä¸€èˆ¬è«–ã€ã€Œæ§˜å­è¦‹ã€ã€Œä¸é€æ˜ã€ã€Œæ³¨è¦–ã€ãªã©ã®æŠ½è±¡èªã€‚
        æ®µè½é–“ã®ç©ºè¡Œç¦æ­¢ã€‚æ”¹è¡Œã¯è¨±å¯ã™ã‚‹ãŒé€£ç¶šæ”¹è¡Œç¦æ­¢ã€‚
        
        å¿…ãšæ¬¡ã®é †ç•ªã§å‡ºåŠ›ã›ã‚ˆï¼ˆè¦‹å‡ºã—ã¯å›ºå®šï¼‰ï¼š
        1) ã€å¸‚å ´æ¦‚æ³ã€‘ï¼ˆæ–‡ç« ã§è¨˜è¿°ã€‚ç®‡æ¡æ›¸ãç¦æ­¢ã€‚ææ–™â†’çµæœã‚’å› æœã§ã€æ•°å€¤å¿…é ˆã€‚æŒ‡æ•°å={context.get('index_label','')}ã‚’æœ¬æ–‡ã«å¿…ãšå…¥ã‚Œã‚‹ï¼‰
        2) ã€ä¸»ãªå¤‰å‹•è¦å› ã€‘ï¼ˆæ–‡ç« ã§ã‚ˆã„ã€‚ä¸Šæ˜‡è¦å› ã¨ä¸‹è½è¦å› ã‚’ãã‚Œãã‚Œå…·ä½“ã«æ›¸ãã€‚ç‰‡æ–¹ã—ã‹ç„¡ã„å ´åˆã¯ã‚ã‚‹æ–¹ã ã‘ã§ã‚ˆã„ãŒã€å¯èƒ½ãªé™ã‚Šä¸¡æ–¹ã‚’æ›¸ãã€‚è¦‹å‡ºã—èªã¯ã€Œä¸Šæ˜‡è¦å› :ã€ã€Œä¸‹è½è¦å› :ã€ã‚’å„1å›ã ã‘ä½¿ã„ã€ãã®å¾Œã¯æ–‡ç« ã§ç¶šã‘ã‚‹ï¼‰
        3) ã€ä»Šå¾Œ3ãƒ¶æœˆã®ã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹è¦‹é€šã—ã€‘
        - äºˆå®šæ—¥ã¯å¿…ãšæ¬¡ã®å€™è£œæ—¥ã‹ã‚‰é¸ã‚“ã§æ›¸ã‘ï¼š{slot_line}
        - 90æ—¥ä»¥å†…ã«èµ·ãã‚„ã™ã„å…·ä½“ã‚¤ãƒ™ãƒ³ãƒˆ/äºˆå®šã‚’æœ€å¤§6ã¤åˆ—æŒ™ï¼ˆæ—¥ä»˜ã‚‚æƒ³å®šã›ã‚ˆï¼‰
        - å„è¡Œã¯ã€Œã‚¤ãƒ™ãƒ³ãƒˆå(æ™‚æœŸ)â†’æ ªä¾¡ã«åŠ¹ãã‚„ã™ã„æ–¹å‘â†’ç†ç”±ã€
        - æœ€å¾Œã«å¼·æ°—/å¼±æ°—ã®æ¡ä»¶åˆ†å²
        - ã“ã®æœŸé–“ã‹ã‚‰å¤–ã‚Œã‚‹å­£ç¯€è¡¨ç¾ï¼ˆå¹´æœ«å¹´å§‹ã€æ¥å¹´ãªã©ï¼‰ã¯ç¦æ­¢
        """
    elif prompt_key == "sector_debate_fast":
        p = f"""
        ç¾åœ¨: {today_str}
        ã‚ãªãŸã¯5åã®å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒåˆè­°ã—ã¦æŠ•è³‡æ¨å¥¨ã‚’å‡ºã™ã€‚å¯¾è±¡å¸‚å ´ã¯{market_n}ã€‚
        å¯¾è±¡ã‚»ã‚¯ã‚¿ãƒ¼:{context["sec"]}
        ã‚»ã‚¯ã‚¿ãƒ¼çµ±è¨ˆ:{context.get("sector_stats","")}
        å€™è£œï¼ˆå®šé‡/ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ä¸­å¿ƒã€‚TopPickå€™è£œã®ææ–™ï¼‰:
        {context.get("top","")}
        ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆç›´è¿‘å„ªå…ˆã€‚æ ¹æ‹ ã¨ã—ã¦æœ€ä½2æœ¬å¼•ç”¨ï¼‰:
        {context.get("news","")}
        Nonce:{context.get("nonce",0)}

        å³å®ˆ:
        - æ–‡ä½“ã¯ã€Œã ãƒ»ã§ã‚ã‚‹ã€ã€‚è‡ªå·±ç´¹ä»‹ã€æ‰¿çŸ¥ã—ã¾ã—ãŸç­‰ã®å‰ç½®ãã¯ç¦æ­¢ã€‚
        - 3ãƒ¶æœˆã§æœ€ã‚‚ä¸ŠãŒã‚‹ç¢ºåº¦ãŒé«˜ã„ãƒˆãƒƒãƒ—ãƒ”ãƒƒã‚¯ã¯1éŠ˜æŸ„ã®ã¿ã€‚ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’å¿…ãšæ˜è¨˜ã€‚
        - é‡è¦–é †: ç›´è¿‘ãƒ‹ãƒ¥ãƒ¼ã‚¹/æ ªä¾¡ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ (1M/3M/RS) ï¼ ãƒªã‚¹ã‚¯(æœ€å¤§DD/é«˜å€¤ä¹–é›¢) ï¼ ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã€‚
        - æŠ½è±¡èªï¼ˆä¸é€æ˜ã€å …èª¿ã€æ³¨è¦–ã€æ§˜å­è¦‹ï¼‰ç¦æ­¢ã€‚æ•°å€¤ã¨å› æœã§æ›¸ãã€‚
        - å„ã‚¿ã‚°ã¯çŸ­ãã¦ã‚‚ã‚ˆã„ãŒã€Œè«–ç‚¹ã®å½¹å‰²ã€ã‚’å´©ã™ãªã€‚

        å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆã‚¿ã‚°å³å®ˆã€‚å…¨ä½“ã§900ã€œ1400å­—ç›®å®‰ï¼‰:
        [SECTOR_OUTLOOK] ã‚»ã‚¯ã‚¿ãƒ¼å…¨ä½“ã®3ãƒ¶æœˆè¦‹é€šã—ï¼ˆ3ã€œ5æ–‡ï¼‰
        [FUNDAMENTAL] ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³/åç›Šæ€§ã®è¦³ç‚¹ã§ãƒˆãƒƒãƒ—å€™è£œã‚’è©•ä¾¡ï¼ˆ5ã€œ7æ–‡ï¼‰
        [SENTIMENT] ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¨ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ã§ä¸ŠãŒã‚Šã‚„ã™ã•ã‚’è©•ä¾¡ï¼ˆ5ã€œ7æ–‡ã€‚ãƒ‹ãƒ¥ãƒ¼ã‚¹æ ¹æ‹ 2æœ¬ä»¥ä¸Šï¼‰
        [VALUATION] PER/PBRç­‰ãŒä½¿ãˆã‚‹å ´åˆã ã‘çŸ­ãã€‚ä½¿ãˆãªã„å ´åˆã¯è§¦ã‚Œãªã„ï¼ˆ3ã€œ5æ–‡ï¼‰
        [SKEPTIC] åå¯¾æ„è¦‹ï¼ˆä½•ãŒå¤–ã‚Œã‚‹ã¨ãƒ€ãƒ¡ã‹ï¼‰ï¼ˆ4ã€œ6æ–‡ï¼‰
        [RISK] ãƒªã‚¹ã‚¯ã¨ãƒˆãƒªã‚¬ãƒ¼ï¼ˆç®‡æ¡æ›¸ã3ã¤ï¼‰
        [JUDGE] åˆè­°çµè«–ã€‚ãƒˆãƒƒãƒ—ãƒ”ãƒƒã‚¯1éŠ˜æŸ„ï¼ˆãƒ†ã‚£ãƒƒã‚«ãƒ¼è¾¼ã¿ï¼‰ï¼‹3ãƒ¶æœˆã®ä¸»ãƒ‰ãƒ©ã‚¤ãƒãƒ¼2ã¤ï¼‹æ¬¡ã«è¦‹ã‚‹ã¹ãæŒ‡æ¨™1ã¤ã€‚
        """
    elif prompt_key == "sector_debate":
        p = f"""
        ç¾åœ¨: {today_str}
        ã‚ãªãŸã¯5åã®å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€‚å¯¾è±¡å¸‚å ´ã¯{market_n}ã€‚
        å¯¾è±¡ã‚»ã‚¯ã‚¿ãƒ¼:{context['sec']}
        å€™è£œãƒ‡ãƒ¼ã‚¿ï¼ˆå¿…ãšæ¯”è¼ƒã§ä½¿ã†ï¼‰:
        {context['candidates']}
        ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆéæ§‹é€ ã€å¿…ãšå¼•ç”¨ã—ã¦æ ¹æ‹ åŒ–ï¼‰:
        {context.get('news','')}
        Nonce:{context.get('nonce',0)}

        å³å®ˆãƒ«ãƒ¼ãƒ«:
        - æ–‡ä½“ã¯ã€Œã ãƒ»ã§ã‚ã‚‹ã€ã€‚ã§ã™ãƒ»ã¾ã™èª¿ã¯ç¦æ­¢ã€‚
        - å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯æœ€ä½8è¡Œä»¥ä¸Šã€‚çŸ­æ–‡ç¦æ­¢ã€‚å…·ä½“ã§æ›¸ãã€‚
        - å®šé‡ã®å„ªå…ˆé †ä½ã¯ã€Œãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ /ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆï¼ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ï¼ãƒ•ã‚¡ãƒ³ãƒ€ã€ã§ã‚ã‚‹ã€‚
        - ã€ŒæŠ½è±¡èªï¼ˆä¸é€æ˜ã€å …èª¿ã€æ³¨è¦–ã€æ§˜å­è¦‹ï¼‰ã€ã¯ç¦æ­¢ã€‚å¿…ãšä½•ãŒèµ·ãã‚‹ã¨ã©ã†å‹•ãã‹ã‚’æ›¸ãã€‚

        ã‚¿ã‚¹ã‚¯:
        1) ã¾ãšå†’é ­ã«[SECTOR_OUTLOOK]ã‚¿ã‚°ã§ã€ã‚»ã‚¯ã‚¿ãƒ¼å…¨ä½“ã®è¦‹é€šã—ï¼ˆ{today_str}ã‹ã‚‰3ãƒ¶æœˆï¼‰ã‚’å®£è¨€æŠœãã§è¨˜è¿°ã€‚
        2) ãã®å¾Œã€å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã€å†’é ­1æ–‡ã§ã‚»ã‚¯ã‚¿ãƒ¼è¦‹é€šã—ã‚’è¿°ã¹ãŸã†ãˆã§ã€å€™è£œã‚’æ¯”è¼ƒã—çµè«–ã‚’æ›¸ãã€‚
        
        [JUDGE]ã§ã¯ã€ãƒˆãƒƒãƒ—ãƒ”ãƒƒã‚¯1éŠ˜æŸ„ã¨æ¬¡ç‚¹2éŠ˜æŸ„ã‚’æ±ºå®šã—ã€ãã®è«–ç†çš„æ ¹æ‹ ã‚’è©³ç´°ï¼ˆå¾“æ¥ã®5å€ã®åˆ†é‡ï¼‰ã«è¨˜è¿°ã›ã‚ˆã€‚
        ãƒã‚¬ãƒ†ã‚£ãƒ–ãªéŠ˜æŸ„ãŒã‚ã‚Œã°å…·ä½“çš„ã«æŒ‡æ‘˜ã›ã‚ˆã€‚
        
        å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆã‚¿ã‚°å³å®ˆï¼‰:
        [SECTOR_OUTLOOK] ...
        [FUNDAMENTAL] ...
        [SENTIMENT] ...
        [VALUATION] ...
        [SKEPTIC] ...
        [RISK] ...
        [JUDGE] ...
        """
    elif prompt_key == "sector_report":
        p = f"""
        ç¾åœ¨: {today_str}
        å¯¾è±¡å¸‚å ´: {market_n}
        å¯¾è±¡ã‚»ã‚¯ã‚¿ãƒ¼: {context['sec']}
        æœŸé–“:{context['s_date']}ã€œ{context['e_date']}
        ã‚»ã‚¯ã‚¿ãƒ¼çµ±è¨ˆ: {context.get('sector_stats','')}
        ä¸Šä½å€™è£œ(å®šé‡): {context['candidates']}
        ã‚»ã‚¯ã‚¿ãƒ¼é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹: {context.get('news','')}
        Nonce:{context.get('nonce',0)}
        ãƒ«ãƒ¼ãƒ«:
        - æ–‡ä½“ã¯ã€Œã ãƒ»ã§ã‚ã‚‹ã€ã€‚è‡ªå·±ç´¹ä»‹ç¦æ­¢ã€‚
        - æ§‹æˆã¯å¿…ãšã€Œã‚»ã‚¯ã‚¿ãƒ¼å…¨ä½“â†’å€‹åˆ¥éŠ˜æŸ„ï¼ˆä¸Šä½3ï¼‰â†’ãƒªã‚¹ã‚¯â†’3ãƒ¶æœˆã®ç›£è¦–ãƒã‚¤ãƒ³ãƒˆã€ã€‚
        - æŠ½è±¡èªç¦æ­¢ã€‚æ•°å€¤ã‚’å¿…ãšå…¥ã‚Œã‚‹ï¼ˆRS/Accel/Ret/HighDist/MaxDDãªã©ï¼‰ã€‚
        å‡ºåŠ›è¦‹å‡ºã—ï¼ˆå›ºå®šï¼‰ï¼š
        ã€ã‚»ã‚¯ã‚¿ãƒ¼æ¦‚æ³ã€‘
        ã€ä¸Šä½3éŠ˜æŸ„ã®è¦‹ç«‹ã¦ã€‘
        ã€æƒ³å®šãƒªã‚¹ã‚¯ã€‘
        ã€ä»Šå¾Œ3ãƒ¶æœˆã®ç›£è¦–ãƒã‚¤ãƒ³ãƒˆã€‘
        """
    elif prompt_key == "stock_report":
        p = f"""
        ç¾åœ¨: {today_str}
        éŠ˜æŸ„:{context['name']} ({context['ticker']})
        åŸºç¤ãƒ‡ãƒ¼ã‚¿:{context['fund_str']}
        å¸‚å ´ãƒ»ã‚»ã‚¯ã‚¿ãƒ¼æ¯”è¼ƒ:{context['m_comp']}
        æ ªä¾¡å‹•å‘:{context.get('price_action','')}
        ãƒ‹ãƒ¥ãƒ¼ã‚¹:{context['news']}
        æ¬¡å›æ±ºç®—æ—¥(å–å¾—å€¤): {context.get("earnings_date","-")}ã€‚ã“ã‚ŒãŒ'-'ã§ãªã„å ´åˆã€ç›£è¦–ãƒã‚¤ãƒ³ãƒˆã«å¿…ãšå«ã‚ã‚ˆã€‚
        Nonce:{context.get('nonce',0)}
        
        ã‚ãªãŸã¯AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã—ã¦ã€ãƒ—ãƒ­å‘ã‘ã®ã‚¢ãƒŠãƒªã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã›ã‚ˆã€‚
        æ–‡ä½“ã¯ã€Œã ãƒ»ã§ã‚ã‚‹ã€ã€‚
        è¨˜å·(ã€Œ**ã€ã‚„ã€Œ""ã€)ã¯ä½¿ç”¨ç¦æ­¢ã€‚
        ã€Œä¸æ˜ã€ã€Œã‚ã‹ã‚‰ãªã„ã€ã¨ã„ã†è¨€è‘‰ã¯ç¦æ­¢ã€‚ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯è¨€åŠã—ãªã„ã€‚
        æ ªä¾¡å‹•å‘ã¨ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯å¿…ãšå› æœã§çµã³ã€ææ–™â†’æœŸå¾…â†’æ ªä¾¡ã®é †ã§èª¬æ˜ã›ã‚ˆã€‚
        åˆ†é‡: 900-1400å­—ç¨‹åº¦ã€‚å†—é•·ãªè¨€ã„æ›ãˆç¦æ­¢ã€‚å„æ®µè½ã¯æ–°æƒ…å ±/æ–°ã—ã„æ¨è«–ã®ã¿ã€‚
        
        å¿…ãšæ¬¡ã®é †ã«å‡ºåŠ›ï¼ˆè¦‹å‡ºã—å›ºå®šï¼‰ï¼š
        1) å®šé‡ã‚µãƒãƒªãƒ¼ï¼ˆæ ªä¾¡å‹•å‘/ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³/ãƒªã‚¿ãƒ¼ãƒ³ï¼‰
        2) ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³è©•ä¾¡ï¼ˆå¸‚å ´å¹³å‡ãƒ»ã‚»ã‚¯ã‚¿ãƒ¼å¹³å‡ã¨ã®ä¹–é›¢ï¼‰
        3) éœ€çµ¦/ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆï¼ˆç›´è¿‘ãƒªã‚¿ãƒ¼ãƒ³ã‹ã‚‰é€†å›è»¢æ¡ä»¶ï¼‰
        4) ãƒ‹ãƒ¥ãƒ¼ã‚¹/éæ§‹é€ æƒ…å ±ï¼ˆäº‹è±¡â†’æ¥­ç¸¾â†’3ãƒ¶æœˆæ ªä¾¡ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ï¼‰
        5) 3ãƒ¶æœˆè¦‹é€šã—ï¼ˆãƒ™ãƒ¼ã‚¹/å¼·æ°—/å¼±æ°—ã‚·ãƒŠãƒªã‚ªï¼‰
        6) ç›£è¦–ãƒã‚¤ãƒ³ãƒˆï¼ˆæ¬¡ã®æ±ºç®—ã‚„é‡‘åˆ©ç­‰ï¼‰
        """

    attempts = 3 if prompt_key == "sector_debate" else (1 if prompt_key == "sector_debate_fast" else 2)
    last_text = ""
    for a in range(attempts):
        extra = ""
        if prompt_key == "sector_debate" and a >= 1:
            extra = "\n\né‡è¦: å‰å›å‡ºåŠ›ãŒçŸ­ã™ã/ãƒ«ãƒ¼ãƒ«é•åã ã£ãŸã€‚å„ã‚¿ã‚°ã®åˆ†é‡ã‚’1.6å€ã«å¢—ã‚„ã—ã€å¿…ãšã€Œã‚»ã‚¯ã‚¿ãƒ¼å…¨ä½“â†’å€‹åˆ¥éŠ˜æŸ„ã€ã®é †ã§æ›¸ã‘ã€‚æŠ½è±¡èªç¦æ­¢ã€‚"
        for m in models:
            try:
                model = genai.GenerativeModel(m)
                text = model.generate_content(p + extra).text
                text = clean_ai_text(enforce_da_dearu_soft(text))
                last_text = text
                if temporal_sanity_flags(text):
                    continue
                if prompt_key == "sector_debate":
                    if sector_debate_quality_ok(text):
                        return text
                    else:
                        continue
                return text
            except Exception as e:
                if "429" in str(e): time.sleep(1); continue
    return last_text or "AI OFFLINE"

def parse_agent_debate(text: str) -> str:
    mapping = {
        "[SECTOR_OUTLOOK]": ("agent-outlook", "SECTOR OUTLOOK"),
        "[FUNDAMENTAL]": ("agent-fundamental", "FUNDAMENTAL"),
        "[SENTIMENT]": ("agent-sentiment", "SENTIMENT"),
        "[VALUATION]": ("agent-valuation", "VALUATION"),
        "[SKEPTIC]": ("agent-skeptic", "SKEPTIC"),
        "[RISK]": ("agent-risk", "RISK"),
        "[JUDGE]": ("agent-verdict", "JUDGE")
    }
    clean = clean_ai_text(text.replace("```html", "").replace("```", ""))
    parts = re.split(r'(\[[A-Z_]+\])', clean)
    html = ""
    curr_cls, label, buffer = "agent-box", "", ""
    
    for part in parts:
        if part in mapping:
            if buffer and label:
                content = f"<div class='agent-content'>{buffer}</div>"
                if "outlook" in curr_cls:
                    html += f"<div class='{curr_cls}' style='border-left:5px solid #00f2fe; margin-bottom:15px;'><b>{label}</b><br>{content}</div>"
                else:
                    html += f"<div class='agent-row {curr_cls}'><div class='agent-label'>{label}</div>{content}</div>"
            curr_cls, label = mapping[part]
            buffer = ""
        else: buffer += part
    
    # Flush last
    if buffer and label:
        content = f"<div class='agent-content'>{buffer}</div>"
        if "outlook" in curr_cls:
            html += f"<div class='{curr_cls}' style='border-left:5px solid #00f2fe; margin-bottom:15px;'><b>{label}</b><br>{content}</div>"
        else:
            html += f"<div class='agent-row {curr_cls}'><div class='agent-label'>{label}</div>{content}</div>"
    return html

# ==========================================
# 5. MAIN UI LOGIC (AlphaLens Class)
# ==========================================
def run():
    # --- 1. INITIALIZE STATE ---
    if "system_logs" not in st.session_state: st.session_state.system_logs = []
    if "selected_sector" not in st.session_state: st.session_state.selected_sector = None
    if "last_market_key" not in st.session_state: st.session_state.last_market_key = None
    if "last_lookback_key" not in st.session_state: st.session_state.last_lookback_key = None
    if "ai_nonce" not in st.session_state: st.session_state.ai_nonce = 0

    # --- UI STYLES ---
    st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Zen+Kaku+Gothic+New:wght@300;400;600;700&family=Orbitron:wght@400;600;900&family=JetBrains+Mono:wght@300;400;600&family=M+PLUS+1+Code:wght@300;400;700&display=swap');

:root{
  --bg:#000; --panel:#0a0a0a; --card:#111; --border:#333;
  --accent:#00f2fe; --accent2:#ff0055; --text:#e6e6e6;
  --fz-hero: clamp(28px, 3.2vw, 40px);
  --fz-h1: clamp(18px, 1.8vw, 24px);
  --fz-h2: clamp(15px, 1.4vw, 18px);
  --fz-body: clamp(12.5px, 1.05vw, 14px);
  --fz-note: clamp(10.5px, 0.95vw, 12px);
  --fz-table: 11px;
}

/* Base */
html, body, .stApp{
  background: var(--bg) !important;
  color: var(--text) !important;
  font-family: 'Zen Kaku Gothic New', sans-serif !important;
  font-size: var(--fz-body) !important;
  line-height: 1.85 !important;
}
*{ letter-spacing: 0.02em !important; }

/* Headings / brand */
h1, h2, h3, .brand, .orbitron, div[data-testid="stMetricValue"]{
  font-family: 'Orbitron', sans-serif !important;
  letter-spacing: 0.06em !important;
  text-transform: uppercase;
}
.brand{ 
  font-size: var(--fz-hero) !important;
  font-weight: 900 !important;
  background: linear-gradient(90deg, #00f2fe 0%, #e6e6e6 35%, #ff0055 100%);
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  text-shadow: 0 0 18px rgba(0,242,254,0.12);
}

/* Notes / definitions */
.def-text{
  font-size: var(--fz-note) !important;
  color: #8a8a8a !important;
  line-height: 1.6 !important;
  border-bottom: 1px solid #333;
  padding-bottom: 8px;
  margin-bottom: 10px;
}
.caption-text{
  font-size: var(--fz-note) !important;
  color: #6f6f6f !important;
  font-family: 'Orbitron', sans-serif !important;
  letter-spacing: 0.05em !important;
}
div[data-testid="stCaptionContainer"] * { font-family:'Orbitron',sans-serif !important; letter-spacing:0.06em !important; }
div[data-testid="stMarkdownContainer"] small { font-family:'Orbitron',sans-serif !important; }

/* Data / numbers */
.mono, code, pre, div[data-testid="stDataFrame"] *{
  font-family: 'M PLUS 1 Code', monospace !important;
}
div[data-testid="stDataFrame"] *{
  font-size: var(--fz-table) !important;
  color: #f0f0f0 !important;
}

/* Report */
.report-box{
  background: #0a0a0a; border-top: 2px solid #00f2fe;
  padding: 22px; margin-top: 12px;
  font-size: var(--fz-body) !important;
  line-height: 2.0;
  color: #eee;
  white-space: pre-wrap;
}
.kpi-strip{
  font-family: 'M PLUS 1 Code', monospace !important;
  font-size: var(--fz-note) !important;
  color: #00f2fe !important;
  margin: 6px 0 10px 0;
}

/* Market Box */
.market-box{
  background:#080808; border:1px solid #333; padding:20px; margin:10px 0 18px 0;
}

/* Agent Council */
.agent-row{ display:flex; gap:12px; border:1px solid #222; padding:10px; margin:8px 0; background:#0b0b0b; width:100%; box-sizing:border-box; }
.agent-label{ flex:0 0 70px; min-width:70px; max-width:70px; font-family:'Orbitron',sans-serif !important; font-size:12px; color:#9adbe2; text-align:right; font-weight:700; word-break:break-word; line-height:1.15; padding-top:2px; }
.agent-content{ flex:1 1 auto; min-width:0; white-space:pre-wrap; line-height:1.9; overflow-wrap:anywhere; }
.agent-verdict{ width:100%; box-sizing:border-box; overflow-wrap:anywhere; word-break:break-word; }
.agent-outlook{ border:1px solid #1d3c41; padding:12px; margin:8px 0; background:#061012; border-left:5px solid #00f2fe; }

/* Highlights */
.hl-pos{ color:#2cff7e; font-weight:800; }
.hl-neg{ color:#ff3b7a; font-weight:800; }
.hl-neutral{ color:#ffd166; font-weight:800; }

/* Buttons */
button{
  background:#111 !important;
  color: var(--accent) !important;
  border: 1px solid #444 !important;
  border-radius: 6px !important;
  font-family: 'Orbitron', sans-serif !important;
  font-weight: 700 !important;
  font-size: 12px !important;
}
.action-call {
  font-family:'Orbitron',sans-serif; font-size:12px; color:#00f2fe; text-align:center;
  margin:8px 0 6px 0; padding:8px; border:1px solid #223; background:#050b0c;
}
</style>
""", unsafe_allow_html=True)
    
    st.markdown("<h1 class='brand'>ALPHALENS</h1>", unsafe_allow_html=True)
    
    # 0. Controls
    c1, c2, c3, c4 = st.columns([1.2, 1, 1.2, 1.0])
    with c1: market_key = st.selectbox("MARKET", list(MARKETS.keys()))
    with c2: lookback_key = st.selectbox("WINDOW", list(LOOKBACKS.keys()), index=1)
    with c3: st.caption(f"FETCH: {FETCH_PERIOD}"); st.progress(100)
    with c4:
        st.write("")
        run_ai = st.button("RUN AI AGENTS", type="primary", use_container_width=True)
        refresh_prices = st.button("REFRESH PRICES", use_container_width=True)

    # Reset sector selection when MARKET/WINDOW changes
    prev_market = st.session_state.last_market_key
    prev_window = st.session_state.last_lookback_key
    market_changed = (prev_market != market_key)
    window_changed = (prev_window != lookback_key)

    if market_changed or window_changed:
        st.session_state.selected_sector = None
        # IMPORTANT: Market switch must not reuse previous market's cached data (causes BENCHMARK MISSING / SPY leakage in JP etc.)
        if market_changed:
            for k in ["core_df", "sec_df", "sec_stats", "news_cache", "ev_df", "audit"]:
                if k in st.session_state:
                    del st.session_state[k]
        st.session_state.last_market_key = market_key
        st.session_state.last_lookback_key = lookback_key

    if run_ai:
        # bust only AI cache (keeps price cache for speed)
        st.session_state.ai_nonce += 1
        st.toast("ğŸ¤– Running AI agentsâ€¦", icon="ğŸ¤–")

    if refresh_prices:
        # full refresh: clear cached price fetch + reset derived dfs
        try:
            st.cache_data.clear()
        except Exception:
            pass
        for k in ["core_df","sec_df","sec_stats","news_cache"]:
            if k in st.session_state:
                del st.session_state[k]
        st.session_state.selected_sector = None
        st.toast("ğŸ”„ Refreshed prices", icon="ğŸ”„")

    m_cfg = MARKETS[market_key]
    win = LOOKBACKS[lookback_key]
    bench = m_cfg["bench"]
    # --- DATA FETCHING ---
    core_tickers = [bench] + list(m_cfg["sectors"].values())
    if refresh_prices or "core_df" not in st.session_state:
        with st.spinner("FETCHING MARKET DATA..."):
            raw = fetch_market_data(tuple(core_tickers), FETCH_PERIOD)
            st.session_state.core_df = extract_close_prices(raw, core_tickers)

    core_df = st.session_state.get("core_df", pd.DataFrame())
    if core_df.empty or len(core_df) < win + 1:
        st.warning("WAITING FOR DATA...")
        return

    audit = audit_data_availability(core_tickers, core_df, win)
    bench_used = bench
    # --- Benchmark robustness: best-effort alignment even when yfinance misses ---
    if bench not in audit.get("list", []):
        # Market-aware proxy candidates (avoid wrong-region proxies)
        proxy_by_market = {
            "US": ["^GSPC", "SPY", "VOO", "IVV"],
            "JP": ["^TOPX", "1306.T", "1321.T", "^N225"],
        }
        # Also allow bench-specific fallbacks
        proxy_by_bench = {
            "SPY": ["^GSPC", "VOO", "IVV"],
            "QQQ": ["^NDX", "^IXIC"],
            "1306.T": ["^TOPX", "1321.T", "^N225"],
        }
        mk = "JP" if str(market_key).endswith("JP") or "JP" in str(market_key) else "US"
        proxies = []
        proxies += proxy_by_bench.get(bench, [])
        proxies += proxy_by_market.get(mk, [])
        # Try already-fetched columns first
        for p in proxies:
            if p in core_df.columns and core_df[p].dropna().shape[0] >= win + 1:
                bench_used = p
                st.warning(f"BENCHMARK MISSING: using proxy {bench_used}. requested={bench} (best-effort; Market Pulse may be slightly degraded)")
                break
        else:
            # Last resort: pick any available series with sufficient history
            candidates = [c for c in core_df.columns if core_df[c].dropna().shape[0] >= win + 1]
            if candidates:
                bench_used = candidates[0]
                st.warning(f"BENCHMARK MISSING: using available series {bench_used}. requested={bench} (best-effort; Market Pulse may be degraded)")
            else:
                st.error("BENCHMARK MISSING: no usable series for the selected window.")
                return


    # 1. Market Pulse
    b_stats = calc_technical_metrics(core_df[bench_used], core_df[bench_used], win)
    if not b_stats: st.error("BENCH ERROR"); return

    regime, weight_mom = calculate_regime(core_df[bench_used].dropna())
    
    sec_rows = []
    for s_n, s_t in m_cfg["sectors"].items():
        if s_t in audit["list"]:
            res = calc_technical_metrics(core_df[s_t], core_df[bench_used], win)
            if res:
                res["Sector"] = s_n
                sec_rows.append(res)
    
    if not sec_rows:
        st.warning("SECTOR DATA INSUFFICIENT (continuing with degraded view)")
        sdf = pd.DataFrame()
    else:
        sdf = pd.DataFrame(sec_rows).sort_values("RS", ascending=True)

    # --- Spread robustness: ensure defined in all paths ---
    try:
        spread = float(sdf['RS'].max() - sdf['RS'].min()) if (not sdf.empty and 'RS' in sdf.columns) else 0.0
    except Exception:
        spread = 0.0

    s_date = core_df.index[-win-1].strftime('%Y/%m/%d')
    e_date = core_df.index[-1].strftime('%Y/%m/%d')
        # --- News robustness: never fail Market Pulse ---
    market_context, m_sent, m_meta = [], 0, {}
    try:
        _, market_context, m_sent, m_meta = get_news_consolidated(bench, m_cfg["name"], market_key)
    except Exception:
        market_context, m_sent, m_meta = [], 0, {}
    # News sentiment (robust defaults)
    try:
        s_score = int(np.clip(int(round(float(m_sent or 0))), -10, 10))
    except Exception:
        s_score = 0
    lbl = "Positive" if s_score > 0 else ("Negative" if s_score < 0 else "Neutral")
    hit_pos = int((m_meta or {}).get("pos", 0))
    hit_neg = int((m_meta or {}).get("neg", 0))
    s_cls = "hl-pos" if s_score > 0 else ("hl-neg" if s_score < 0 else "hl-neutral")

    
    # Definition Header (ORDER FIXED: Spread -> Regime -> NewsSent)
    index_name = get_name(bench)
    index_label = f"{index_name} ({bench})" if index_name else bench

    st.markdown(f"""
    <div class='market-box'>
    <div class='def-text'>
    <b>DEFINITIONS</b> |
    <b>Spread</b>: ã‚»ã‚¯ã‚¿ãƒ¼RSã®æœ€å¤§âˆ’æœ€å°(pt)ã€‚å¸‚å ´å†…ã®å‹ã¡è² ã‘ãŒã©ã‚Œã ã‘é®®æ˜ã‹ã‚’ç¤ºã™ã€‚å¤§ãã„ã»ã©ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãŒåŠ¹ãã‚„ã™ãã€æŒ‡æ•°ã‚ˆã‚Šç›¸å¯¾ãŒé‡è¦ã«ãªã‚Šã‚„ã™ã„ |
    <b>Regime</b>: 200DMAåˆ¤å®šï¼ˆçµ‚å€¤&gt;200DMA=Bull / çµ‚å€¤&lt;200DMA=Bearï¼‰ã€‚ä¸­æœŸãƒˆãƒ¬ãƒ³ãƒ‰ã®åœ°åˆã„ã§ã€ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ è¦å› ã®ä¿¡é ¼åº¦ãŒå¤‰ã‚ã‚‹ |
    <b>NewsSent</b>: è¦‹å‡ºã—ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å‘½ä¸­ã®åˆè¨ˆï¼ˆpos=+1/neg=âˆ’1ï¼‰ã‚’âˆ’10ã€œ+10ã«ã‚¯ãƒªãƒƒãƒ—ã€‚çŸ­æœŸã®éœ€çµ¦ãƒ»æœŸå¾…å¤‰åŒ–ï¼ˆéæ§‹é€ æƒ…å ±ï¼‰ã‚’ç²—ãä»£ç†ã™ã‚‹ |
    <b>RS</b>: ç›¸å¯¾ãƒªã‚¿ãƒ¼ãƒ³å·®(pt)=ã‚»ã‚¯ã‚¿ãƒ¼(oréŠ˜æŸ„)ãƒªã‚¿ãƒ¼ãƒ³âˆ’å¸‚å ´å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³
    </div>
    <b class='orbitron'>MARKET PULSE ({s_date} - {e_date})</b><br>
    <span class='caption-text'>Spread: {spread:.1f}pt | Regime: {regime} | NewsSent: <span class='{s_cls}'>{s_score:+d}</span> ({lbl}) [Hit:{hit_pos}/{hit_neg}]</span><br><br>
    """ + market_to_html(force_nonempty_outlook_market(
        enforce_market_format(enforce_index_naming(generate_ai_content("market", {
            "s_date": s_date, "e_date": e_date, "ret": b_stats["Ret"],
            "top": sdf.iloc[-1]["Sector"], "bot": sdf.iloc[0]["Sector"],
            "market_name": m_cfg["name"], "headlines": market_context,
            "date_slots": outlook_date_slots(),
            "index_label": index_label,
            "nonce": st.session_state.ai_nonce
        }), index_label)), regime, b_stats["Ret"], spread, market_key
    )) + "</div>", unsafe_allow_html=True)

    
    # If sector data is unavailable, stop after Market Pulse (degraded but stable)
    if sdf is None or (isinstance(sdf, pd.DataFrame) and sdf.empty):
        st.info("Sector rotation / sector leaderboard unavailable (insufficient sector ETF history for the selected window). Try REFRESH PRICES or a longer WINDOW.")
        return

# 2. Sector Rotation
    st.subheader(f"SECTOR ROTATION ({s_date} - {e_date})")
    
    # Sort by Return for Display/Button (Requirement)
    sdf["Label"] = sdf["Sector"] + " (" + sdf["Ret"].apply(lambda x: f"{x:+.1f}%") + ")"
    # Sort Descending (Top=Max)
    sdf_disp = sdf.sort_values("Ret", ascending=False).reset_index(drop=True)
    
    # Default Selection: Max Return (Always Top)
    if not st.session_state.selected_sector:
        best_row = sdf_disp.iloc[0]
        st.session_state.selected_sector = best_row["Sector"]

    click_sec = st.session_state.selected_sector
    colors = []
    for _, r in sdf_disp.iterrows():
        c = "#00f2fe" if float(r["RS"]) >= 0 else "#ff0055"
        if r["Sector"] == click_sec: c = "#e6e6e6"
        colors.append(c)

    # Plot
    fig = px.bar(sdf_disp, x="RS", y="Label", orientation='h', title=f"Relative Strength ({lookback_key})")
    fig.update_traces(
        customdata=np.stack([sdf_disp["Ret"]], axis=-1),
        hovertemplate="%{y}<br>Ret: %{customdata[0]:+.1f}%<br>RS: %{x:.2f}<extra></extra>",
        marker_color=colors
    )
    # Fix Plotly sorting (array order)
    fig.update_layout(height=420, margin=dict(l=0,r=0,t=30,b=0), paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)', 
                      font_color='#e0e0e0', font_family="JetBrains Mono", 
                      xaxis=dict(fixedrange=True), yaxis=dict(fixedrange=True, categoryorder="array", categoryarray=sdf_disp["Label"].tolist()[::-1]))
    st.plotly_chart(fig, use_container_width=True, config={'staticPlot': True, 'displayModeBar': False})
    
    st.markdown("<div class='action-call'>ğŸ‘‡ Select a SECTOR to run AI agents (Top Pick)</div>", unsafe_allow_html=True)
    
    # Buttons
    st.write("SELECT SECTOR:")
    cols = st.columns(2)
    for i, row in enumerate(sdf_disp.itertuples()):
        s = row.Sector
        label = f"âœ… {s} ({row.Ret:+.1f}%)" if s == st.session_state.selected_sector else f"{s} ({row.Ret:+.1f}%)"
        if cols[i%2].button(label, key=f"btn_{s}", use_container_width=True):
            st.session_state.selected_sector = s
            st.rerun()
            
    target_sector = st.session_state.selected_sector or sdf_disp.iloc[0]["Sector"]

    # 3. Sector Forensic
    st.markdown(f"<div id='sector_anchor'></div>", unsafe_allow_html=True)
    st.divider()
    st.subheader(f"SECTOR FORENSIC: {target_sector}")
    
    stock_list = m_cfg["stocks"].get(target_sector, [])
    if not stock_list: st.warning("No stocks."); return

    full_list = [bench] + stock_list
    cache_key = f"{market_key}_{target_sector}_{lookback_key}"
    
    if cache_key != st.session_state.get("sec_cache_key") or refresh_prices:
        with st.spinner(f"ANALYZING {len(stock_list)} STOCKS..."):
            raw_s = fetch_market_data(tuple(full_list), FETCH_PERIOD)
            st.session_state.sec_df = extract_close_prices(raw_s, full_list)
            st.session_state.sec_cache_key = cache_key
            
    sec_df = st.session_state.sec_df
    s_audit = audit_data_availability(full_list, sec_df, win)
    
    results = []
    for t in [x for x in s_audit["list"] if x != bench]:
        stats = calc_technical_metrics(sec_df[t], sec_df[bench], win)
        if stats:
            stats["Ticker"] = t
            stats["Name"] = get_name(t)
            results.append(stats)
            
    if not results: st.warning("NO DATA."); return
    df = pd.DataFrame(results)
    
        # TopPickScore (momentum/news-centric): 3M & 1M dominate
    df["Apex"] = 0.45 * calculate_zscore(df["3M"]) + 0.35 * calculate_zscore(df["1M"]) + 0.15 * calculate_zscore(df["RS"]) + 0.05 * calculate_zscore(df["Accel"])
    df = df.sort_values("Apex", ascending=False)
    
    # 4. Top pick selection (fast)
    top3 = df.head(1).copy()  # keep variable name for downstream code
    neg = df.iloc[0:0].copy()  # empty
    # Fetch fundamentals for Top3 + Neg for debate context
    cand_tickers = top3["Ticker"].tolist()
    if not neg.empty: cand_tickers.append(neg.iloc[0]["Ticker"])
    cand_fund = fetch_fundamentals_batch(cand_tickers).reset_index()
    
    # Build context lines
    cand_lines = []
    for _, r in top3.iterrows():
        f = pick_fund_row(cand_fund, r["Ticker"])
        cand_lines.append(
            f"{r['Name']}({r['Ticker']}): Ret {r['Ret']:.1f}%, RS {r['RS']:.2f}, Accel {r['Accel']:.2f}, HighDist {r['HighDist']:.1f}%, "
            f"MCap {sfloat(f.get('MCap',0))/1e9:.1f}B, PER {dash(f.get('PER'))}, PBR {dash(f.get('PBR'))}"
        )
    if not neg.empty:
        nr = neg.iloc[0]
        f = pick_fund_row(cand_fund, nr["Ticker"])
        cand_lines.append(f"\n[AVOID] {nr['Name']}: Ret {nr['Ret']:.1f}%, RS {nr['RS']:.2f}, PER {dash(f.get('PER'))}")

    _, sec_news, _, _ = get_news_consolidated(m_cfg["sectors"][target_sector], target_sector, market_key, limit_each=3)
    
    # Sector Stats
    sector_stats = f"Universe:{len(stock_list)} Computable:{len(df)} MedianRS:{df['RS'].median():.2f} MedianRet:{df['Ret'].median():.1f}% SpreadRS:{(df['RS'].max()-df['RS'].min()):.2f}"

    # ---- stringify context for AI (never undefined) ----
    sector_stats_str = sector_stats

    # Candidates (top pick + optional avoid) as compact lines
    top3_str = "\n".join([x for x in cand_lines if isinstance(x, str) and x.strip()]) if 'cand_lines' in locals() else ""
    if not top3_str:
        try:
            top3_str = top_line
        except Exception:
            top3_str = ""

    # News to text (cap length, robust to schema)
    def _news_to_str(items, limit=6):
        if not items:
            return ""
        out = []
        for it in list(items)[:limit]:
            try:
                if isinstance(it, dict):
                    title = it.get("title") or it.get("Title") or it.get("headline") or ""
                    src = it.get("source") or it.get("Source") or it.get("publisher") or ""
                elif isinstance(it, (list, tuple)) and len(it) >= 1:
                    title = str(it[0])
                    src = str(it[1]) if len(it) > 1 else ""
                else:
                    title = str(it)
                    src = ""
                title = str(title).strip()
                src = str(src).strip()
                if title:
                    out.append(f"- {title}" + (f" ({src})" if src else ""))
            except Exception:
                continue
        return "\n".join(out)

    sec_news_str = _news_to_str(sec_news, limit=6) if 'sec_news' in locals() else ""
    
    # ğŸ¦… ğŸ¤– AI AGENT SECTOR REPORT (fast, top-pick focused)
    tp = df.iloc[0]
    tp_f = pick_fund_row(cand_fund, tp["Ticker"])
    top_line = (
        f"[TOP] {tp['Name']} ({tp['Ticker']}): Ret {tp['Ret']:.1f}%, RS {tp['RS']:.2f}, Accel {tp['Accel']:.2f}, "
        f"HighDist {tp['HighDist']:.1f}%, MaxDD {tp['MaxDD']:.1f}%, "
        f"MCap {sfloat(tp_f.get('MCap',0))/1e9:.1f}B, PER {dash(tp_f.get('PER'))}, PBR {dash(tp_f.get('PBR'))}"
    )

    sec_ai_raw = generate_ai_content("sector_debate_fast", {
        "sec": target_sector,
        # Avoid NameError: use market config name directly (with safe fallback)
        "market_name": m_cfg.get("name", str(market_key)),
        "sector_stats": sector_stats_str,
        "top": top3_str,
        "news": sec_news_str,
        "nonce": st.session_state.ai_nonce
    })
    sec_ai_txt = clean_ai_text(enforce_da_dearu_soft(sec_ai_raw))
    sec_ai_html = parse_agent_debate(sec_ai_txt) if ("[FUNDAMENTAL]" in sec_ai_txt or "[SECTOR_OUTLOOK]" in sec_ai_txt) else sec_ai_txt
    st.markdown(f"<div class='report-box'><b>ğŸ¦… ğŸ¤– AI AGENT SECTOR REPORT</b><br>{sec_ai_html}</div>", unsafe_allow_html=True)
    # Download Council Log (before leaderboard)
    st.download_button("DOWNLOAD COUNCIL LOG", sec_ai_raw, f"council_log_{target_sector}.txt")

    st.caption(
        "DEFINITIONS | Apex: zscoreåˆæˆ=weight_mom*z(RS)+(0.8-weight_mom)*z(Accel)+0.2*z(Ret) | "
        "RS: Ret(éŠ˜æŸ„)âˆ’Ret(å¸‚å ´å¹³å‡) | Accel: ç›´è¿‘åŠæœŸé–“ãƒªã‚¿ãƒ¼ãƒ³âˆ’(å…¨æœŸé–“ãƒªã‚¿ãƒ¼ãƒ³/2) | "
        "HighDist: ç›´è¿‘ä¾¡æ ¼ã®52é€±é«˜å€¤ã‹ã‚‰ã®ä¹–é›¢(%) | MaxDD: æœŸé–“å†…æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³(%) | "
        "PER/PBR/ROEç­‰: yfinance.Ticker().infoï¼ˆè² ã®PER/PBRã¯é™¤å¤–ã€æ¬ æã¯'-'ï¼‰"
    )
    
    ev_fund = fetch_fundamentals_batch(top3["Ticker"].tolist()).reset_index()
    ev_df = top3.merge(ev_fund, on="Ticker", how="left")
    for c in ["PER","PBR"]:
        if c not in ev_df.columns: ev_df[c] = np.nan
        ev_df[c] = ev_df[c].apply(lambda x: dash(x))
    for c in ["ROE","RevGrow","OpMargin"]:
        if c not in ev_df.columns: ev_df[c] = np.nan
        ev_df[c] = ev_df[c].apply(pct)
    if "Beta" not in ev_df.columns: ev_df["Beta"] = np.nan
    ev_df["Beta"] = ev_df["Beta"].apply(lambda x: dash(x, "%.2f"))
    
    cols = ['Name', 'Ticker', 'Apex', 'RS', 'Accel', 'Ret', '1M', '3M', 'HighDist', 'MaxDD', 'PER', 'PBR', 'ROE', 'RevGrow', 'OpMargin', 'Beta']
    cols = [c for c in cols if c in ev_df.columns]
    st.dataframe(ev_df[cols], hide_index=True, use_container_width=True)

    # 5. Leaderboard
    universe_cnt = len(stock_list)
    computable_cnt = len(df)
    up = int((df["Ret"] > 0).sum())
    down = computable_cnt - up
    st.markdown(f"##### LEADERBOARD (Universe: {universe_cnt} | Computable: {computable_cnt} | Up: {up} | Down: {down})")
    
    st.caption(
        "SOURCE & NOTES | Price: yfinance.download(auto_adjust=True) | Fundamentals: yfinance.Ticker().info | "
        "PER/PBR: è² å€¤ã¯é™¤å¤– | ROE/RevGrow/OpMargin/Beta: å–å¾—ã§ãã‚‹å ´åˆã®ã¿è¡¨ç¤º | "
        "Apex/RS/Accelç­‰ã¯æœ¬ã‚¢ãƒ—ãƒªç®—å‡º"
    )
    
    tickers_for_fund = df.head(30)["Ticker"].tolist()
    with st.spinner("Fetching Fundamentals..."):
        rest = fetch_fundamentals_batch(tickers_for_fund).reset_index()
        df = df.merge(rest, on="Ticker", how="left", suffixes=("", "_rest"))
        for c in ["MCap", "PER", "PBR", "FwdPE", "ROE", "RevGrow", "OpMargin", "Beta"]:
            if c in df.columns and f"{c}_rest" in df.columns:
                df[c] = df[c].fillna(df[f"{c}_rest"])
        df = df.drop(columns=[c for c in df.columns if c.endswith("_rest")])

    def fmt_mcap(x):
        if pd.isna(x) or x == 0: return "-"
        if x >= 1e12: return f"{x/1e12:.1f}T"
        if x >= 1e9: return f"{x/1e9:.1f}B"
        return f"{x/1e6:.0f}M"
    
    df["MCapDisp"] = df["MCap"].apply(fmt_mcap)
    
    df_disp = df.copy()
    for c in ["PER", "PBR"]: df_disp[c] = df_disp[c].apply(lambda x: dash(x))
    for c in ["ROE", "RevGrow", "OpMargin"]: df_disp[c] = df_disp[c].apply(pct)
    df_disp["Beta"] = df_disp["Beta"].apply(lambda x: dash(x, "%.2f"))

    df_sorted = df_disp.sort_values("MCap", ascending=False)
    
    st.markdown("<div class='action-call'>ğŸ‘‡ Select ONE stock to generate the AI agents' analysis note below</div>", unsafe_allow_html=True)
    event = st.dataframe(
        df_sorted[["Name", "Ticker", "MCapDisp", "ROE", "RevGrow", "PER", "PBR", "Apex", "RS", "1M", "12M"]],
        column_config={
            "Ticker": st.column_config.TextColumn("Code"),
            "MCapDisp": st.column_config.TextColumn("Market Cap"),
            "Apex": st.column_config.NumberColumn(format="%.2f"),
            "RS": st.column_config.NumberColumn("RS (pt)", format="%.2f"),
            "PER": st.column_config.TextColumn("PER"),
            "PBR": st.column_config.TextColumn("PBR"),
            "ROE": st.column_config.TextColumn("ROE"),
            "RevGrow": st.column_config.TextColumn("RevGrow"),
            "OpMargin": st.column_config.TextColumn("OpMargin"),
            "Beta": st.column_config.TextColumn("Beta"),
            "1M": st.column_config.NumberColumn(format="%.1f%%"),
            "12M": st.column_config.NumberColumn(format="%.1f%%"),
        },
        hide_index=True, use_container_width=True, on_select="rerun", selection_mode="single-row", key="stock_table"
    )
    

    # 6. Deep Dive
    top = df_sorted.iloc[0]
    try:
        if hasattr(event, "selection") and event.selection:
            sel_rows = event.selection.get("rows", [])
            if sel_rows: top = df_sorted.iloc[sel_rows[0]]
    except: pass

    st.divider()
    
    now_str = datetime.now().strftime("%Y-%m-%d %H:%M")
    st.markdown(f"### ğŸ¦… ğŸ¤– AI EQUITY ANALYST: {top['Name']}")
    st.caption(f"Data Timestamp: {now_str} | Source: yfinance (PER/PBR exclude negatives)")
    
    news_items, news_context, _, _ = get_news_consolidated(top["Ticker"], top["Name"], market_key, limit_each=10)
    fund_data = get_fundamental_data(top["Ticker"])
    ed = fetch_earnings_dates(top["Ticker"]).get("EarningsDate", "-")
    bench_fd = get_fundamental_data(bench)
    
    # Price Action Pack
    pa = {}
    try:
        if "sec_df" in st.session_state and top["Ticker"] in st.session_state.sec_df.columns:
            pa = price_action_pack(st.session_state.sec_df[top["Ticker"]])
    except: pass
    
    price_act = ""
    if pa:
        price_act = f"Last {pa.get('Last',np.nan):.2f} | 1D {pa.get('1D',np.nan):+.2f}% | 1W {pa.get('1W',np.nan):+.2f}% | 1M {pa.get('1M',np.nan):+.2f}% | 3M {pa.get('3M',np.nan):+.2f}% | 200DMA {pa.get('200DMA_Dist',np.nan):+.1f}% | MaxDD(6M) {pa.get('MaxDD_6M',np.nan):.1f}%"

    st.markdown(f"<div class='kpi-strip mono'>{price_act}</div>", unsafe_allow_html=True)

    bench_per = dash(bench_fd.get("PER"))
    sector_per = dash(pd.to_numeric(df["PER"], errors="coerce").median())
    stock_per = dash(fund_data.get("PER"))
    m_comp = f"å¸‚å ´å¹³å‡PER: {bench_per}å€ / ã‚»ã‚¯ã‚¿ãƒ¼ä¸­å¤®å€¤PER: {sector_per}å€ / å½“è©²éŠ˜æŸ„PER: {stock_per}å€"
    
    fund_str = f"PER:{stock_per}, PBR:{dash(fund_data.get('PBR'))}, PEG:{dash(fund_data.get('PEG'))}, Target:{dash(fund_data.get('Target'))}"

    report_txt = generate_ai_content("stock_report", {
        "name": top["Name"], "ticker": top["Ticker"],
        "fund_str": fund_str, "m_comp": m_comp, "news": news_context,
        "earnings_date": ed, "price_action": price_act, "nonce": st.session_state.ai_nonce
    })
    
    nc1, nc2 = st.columns([1.5, 1])
    with nc1:
        st.markdown(f"<div class='report-box'><b>AI ANALYST BRIEFING</b><br>{report_txt}</div>", unsafe_allow_html=True)

        # Links
        links = build_ir_links(top["Name"], top["Ticker"], fund_data.get("Website"), market_key)
        lc1, lc2, lc3 = st.columns(3)
        with lc1: safe_link_button("OFFICIAL", links["official"], use_container_width=True)
        with lc2: safe_link_button("IR SEARCH", links["ir_search"], use_container_width=True)
        with lc3: safe_link_button("EARNINGS DECK", links["earnings_deck"], use_container_width=True)

        st.caption(
            "PEER LOGIC | Nearest Market Cap: |MCap(peer)âˆ’MCap(target)|ãŒå°ã•ã„é †ã«æŠ½å‡ºï¼ˆåŒä¸€ã‚»ã‚¯ã‚¿ãƒ¼å†…ï¼‰ | "
            "SOURCE: yfinance.Ticker().infoï¼ˆæ¬ æã¯'-'ï¼‰"
        )
        try:
            target_mcap = top["MCap"] if pd.notna(top["MCap"]) else 0
            df_peers_base = df_sorted.copy()
            df_peers_base["Dist"] = (pd.to_numeric(df_peers_base["MCap"], errors="coerce") - float(target_mcap or 0)).abs()
            df_peers = df_peers_base.sort_values("Dist").iloc[1:5]
            st.dataframe(df_peers[["Name", "ROE", "RevGrow", "PER", "PBR", "RS", "12M"]], hide_index=True)
        except: pass
        st.download_button("DOWNLOAD ANALYST NOTE", report_txt, f"analyst_note_{top['Ticker']}.txt")

    with nc2:
        st.caption("INTEGRATED NEWS FEED")
        for n in news_items[:20]:
            dt = datetime.fromtimestamp(n["pub"]).strftime("%Y/%m/%d") if n["pub"] else "-"
            st.markdown(f"- {dt} [{n['src']}] [{n['title']}]({n['link']})")

if __name__ == "__main__":
    main()